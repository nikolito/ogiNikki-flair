{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair-nikki-train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikolito/ogiNikki_flair/blob/main/flair_nikki_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLPvhxN4jW9s"
      },
      "source": [
        "# **Named Entity Recognition (NER) for Ogihan Nikki Mokuroku titles**\n",
        "\n",
        "  This script is based on Flair modeling scripts (https://colab.research.google.com/drive/1Mi8GN_x_jQUgOCDjkkjtlN_OXXO3dCF7) created by Hironsan. We try to extract NER class such as persons, places, roles etc. from titles on Ogihan Nikki Database (OND). Please refer to https://crch.dl.saga-u.ac.jp/nikki/ for further information.\n",
        "  OND has a corpus of ca. 74000 sentences that freely available under the Creative Commons CC BY-NC-SA 4.0. We have prepared OND corpus approximately 40000 sentences with NER annotation labels. Thanks to Google Colaboratory, we can create models with up to 30000 sentences here. (Please reduce the mini batch size from 32 to 16 preventing OOM in case of 30000 sentences. )\n",
        "  Once creating a model, you can deploy NER with titles on OND. We recommend that you try \"uid\" 40000 or later for real prediction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4hFsbOx2bSm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "51954993-56dd-4b68-ae13-b705d7465cad"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Oct 27 17:06:40 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0AngDOrZWQr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8527b5d8-5ed3-4b3d-b4a3-0e70bbc12aba"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/19/902d1691c1963ab8c9a9578abc2d65c63aa1ecf4f8200143b5ef91ace6f5/flair-0.6.1-py3-none-any.whl (331kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 8.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 28.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Collecting transformers>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 57.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 52.6MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/01/47358efec5396fc80f98273c42cbdfe7aab056252b07884ffcc0f118978f/konoha-4.6.2-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0+cu101)\n",
            "Collecting pytest>=5.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/36/9e022b76a3ac440e1d750c64fa6152469f988efe0c568b945e396e2693b5/pytest-6.1.1-py3-none-any.whl (272kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 59.0MB/s \n",
            "\u001b[?25hCollecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 50.9MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (3.0.12)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 59.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.0->flair) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.2.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (3.0.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.17.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Collecting overrides==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (2.0.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.10.1)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.9.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.1.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.2.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers>=3.0.0->flair) (50.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.0->flair) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.0->flair) (2020.6.20)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.3.1)\n",
            "Building wheels for collected packages: ftfy, mpld3, segtok, sqlitedict, langdetect, sacremoses, overrides\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45612 sha256=943e0416806713884d2ba09e64162bc897cdfde10b389b80aed047fead460a59\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116677 sha256=e8150150f9065d9c9690eb6e0754c76aa87bbb8ba19ae3a885be807bab6c1246\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25021 sha256=0b351d16d4e13d7d4f1ee5814b48f6c48ae7b78ffaa2880a445a8cde892e465a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp36-none-any.whl size=14377 sha256=b94d8cbd7bc4f192f97e6cae778845104c20fb5fabf8e20cc19d5421e561b6bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=085bcf0b0bd31a7b6794f94f666eba697442f66e99234f0b7fb358d92df39b34\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=831ec2f8bf8ebe3b6849c014061bbe32393db285218f6236a5d30fdfec2cefd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=42364c3815b227e4e7bd69ce919e23a09d61ad70629ded9d82d2059293d43861\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "Successfully built ftfy mpld3 segtok sqlitedict langdetect sacremoses overrides\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers, ftfy, mpld3, segtok, sqlitedict, overrides, konoha, bpemb, pluggy, pytest, deprecated, langdetect, janome, flair\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.10 flair-0.6.1 ftfy-5.8 janome-0.4.1 konoha-4.6.2 langdetect-1.0.8 mpld3-0.3 overrides-3.0.0 pluggy-0.13.1 pytest-6.1.1 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.94 sqlitedict-1.7.0 tokenizers-0.9.2 transformers-3.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YCS0QofZsYe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f1960222-b1ef-4a8d-d3a5-d45c9e3bc7e3"
      },
      "source": [
        "!wget https://crch.dl.saga-u.ac.jp/nikki/dataset/iob-10000-3.txt\n",
        "iob_file = 'iob-10000-3.txt'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-27 17:07:20--  https://crch.dl.saga-u.ac.jp/nikki/dataset/iob-10000-3.txt\n",
            "Resolving crch.dl.saga-u.ac.jp (crch.dl.saga-u.ac.jp)... 153.127.22.73\n",
            "Connecting to crch.dl.saga-u.ac.jp (crch.dl.saga-u.ac.jp)|153.127.22.73|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1687296 (1.6M) [text/plain]\n",
            "Saving to: ‘iob-10000-3.txt.1’\n",
            "\n",
            "iob-10000-3.txt.1   100%[===================>]   1.61M  1.82MB/s    in 0.9s    \n",
            "\n",
            "2020-10-27 17:07:22 (1.82 MB/s) - ‘iob-10000-3.txt.1’ saved [1687296/1687296]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_CwrUxTZ6TI"
      },
      "source": [
        "from flair.datasets import ColumnCorpus\n",
        "from flair.embeddings import StackedEmbeddings, FlairEmbeddings\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYQ7Ct8uZ9ev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "adbd2e62-4e7e-4951-f9c0-5a8f47f599bb"
      },
      "source": [
        "columns = {0: 'text', 1: 'ner'}\n",
        "data_folder = '.'\n",
        "corpus = ColumnCorpus(data_folder, columns,\n",
        "                      train_file=iob_file)\n",
        "print(corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 17:07:28,090 Reading data from .\n",
            "2020-10-27 17:07:28,092 Train: iob-10000-3.txt\n",
            "2020-10-27 17:07:28,096 Dev: None\n",
            "2020-10-27 17:07:28,097 Test: None\n",
            "Corpus: 8100 train + 900 dev + 1000 test sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIve_eCyaI-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0e756433-db76-4137-f8f6-bfe7d1808fae"
      },
      "source": [
        "tag_type = 'ner'\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "print(tag_dictionary.idx2item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'<unk>', b'O', b'B-PLACE', b'I-PLACE', b'B-TERMS', b'I-TERMS', b'B-JINMEI', b'I-JINMEI', b'B-EVENT', b'I-EVENT', b'B-ROLE', b'I-ROLE', b'B-QUANTITY', b'I-QUANTITY', b'B-DATE', b'I-DATE', b'<START>', b'<STOP>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHA3-cbNaLuc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "cc0174e7-3d33-4be9-f958-d9a5dde76ff1"
      },
      "source": [
        "embedding_types = [\n",
        "    FlairEmbeddings('ja-forward',with_whitespace = False),\n",
        "    FlairEmbeddings('ja-backward',with_whitespace = False),\n",
        "]\n",
        "embeddings = StackedEmbeddings(embeddings=embedding_types)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 17:07:30,654 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/japanese-forward.pt not found in cache, downloading to /tmp/tmpujxrs1hz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 335383050/335383050 [00:12<00:00, 26097614.76B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 17:07:43,822 copying /tmp/tmpujxrs1hz to cache at /root/.flair/embeddings/japanese-forward.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 17:07:44,547 removing temp file /tmp/tmpujxrs1hz\n",
            "2020-10-27 17:08:00,444 https://flair.informatik.hu-berlin.de/resources/embeddings/flair/japanese-backward.pt not found in cache, downloading to /tmp/tmpj1esrkzh\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 335383032/335383032 [00:13<00:00, 24889879.68B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 17:08:14,236 copying /tmp/tmpj1esrkzh to cache at /root/.flair/embeddings/japanese-backward.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 17:08:15,130 removing temp file /tmp/tmpj1esrkzh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRRekZ-naN5a"
      },
      "source": [
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=tag_dictionary,\n",
        "                        tag_type=tag_type,\n",
        "                        use_crf=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j57AYAe4ai-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9646eef-75dd-4ad4-a124-8eba2a3e8d11"
      },
      "source": [
        "trainer = ModelTrainer(tagger, corpus)\n",
        "trainer.train('resources/taggers/example-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=150)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 17:08:16,441 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:08:16,443 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.3, inplace=False)\n",
            "        (encoder): Embedding(15174, 100)\n",
            "        (rnn): LSTM(100, 2048, num_layers=2, dropout=0.3)\n",
            "        (decoder): Linear(in_features=2048, out_features=15174, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.3, inplace=False)\n",
            "        (encoder): Embedding(15174, 100)\n",
            "        (rnn): LSTM(100, 2048, num_layers=2, dropout=0.3)\n",
            "        (decoder): Linear(in_features=2048, out_features=15174, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (rnn): LSTM(4096, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=18, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-10-27 17:08:16,443 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:08:16,444 Corpus: \"Corpus: 8100 train + 900 dev + 1000 test sentences\"\n",
            "2020-10-27 17:08:16,445 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:08:16,446 Parameters:\n",
            "2020-10-27 17:08:16,446  - learning_rate: \"0.1\"\n",
            "2020-10-27 17:08:16,448  - mini_batch_size: \"32\"\n",
            "2020-10-27 17:08:16,450  - patience: \"3\"\n",
            "2020-10-27 17:08:16,451  - anneal_factor: \"0.5\"\n",
            "2020-10-27 17:08:16,452  - max_epochs: \"150\"\n",
            "2020-10-27 17:08:16,454  - shuffle: \"True\"\n",
            "2020-10-27 17:08:16,457  - train_with_dev: \"False\"\n",
            "2020-10-27 17:08:16,458  - batch_growth_annealing: \"False\"\n",
            "2020-10-27 17:08:16,459 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:08:16,460 Model training base path: \"resources/taggers/example-ner\"\n",
            "2020-10-27 17:08:16,461 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:08:16,463 Device: cuda:0\n",
            "2020-10-27 17:08:16,464 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:08:16,464 Embeddings storage mode: cpu\n",
            "2020-10-27 17:08:16,467 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:08:27,521 epoch 1 - iter 25/254 - loss 28.06537056 - samples/sec: 72.41 - lr: 0.100000\n",
            "2020-10-27 17:08:37,560 epoch 1 - iter 50/254 - loss 22.38863806 - samples/sec: 79.72 - lr: 0.100000\n",
            "2020-10-27 17:08:48,772 epoch 1 - iter 75/254 - loss 19.55091035 - samples/sec: 71.38 - lr: 0.100000\n",
            "2020-10-27 17:08:59,659 epoch 1 - iter 100/254 - loss 17.59750761 - samples/sec: 73.50 - lr: 0.100000\n",
            "2020-10-27 17:09:10,153 epoch 1 - iter 125/254 - loss 16.22612863 - samples/sec: 76.26 - lr: 0.100000\n",
            "2020-10-27 17:09:21,054 epoch 1 - iter 150/254 - loss 15.16045469 - samples/sec: 73.41 - lr: 0.100000\n",
            "2020-10-27 17:09:32,112 epoch 1 - iter 175/254 - loss 14.30671121 - samples/sec: 72.37 - lr: 0.100000\n",
            "2020-10-27 17:09:43,284 epoch 1 - iter 200/254 - loss 13.50549186 - samples/sec: 71.63 - lr: 0.100000\n",
            "2020-10-27 17:09:53,779 epoch 1 - iter 225/254 - loss 12.84415662 - samples/sec: 76.25 - lr: 0.100000\n",
            "2020-10-27 17:10:04,049 epoch 1 - iter 250/254 - loss 12.30479287 - samples/sec: 77.92 - lr: 0.100000\n",
            "2020-10-27 17:10:05,298 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:10:05,299 EPOCH 1 done: loss 12.2330 - lr 0.1000000\n",
            "2020-10-27 17:10:16,290 DEV : loss 5.599512577056885 - score 0.7499\n",
            "2020-10-27 17:10:16,336 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:10:19,362 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:10:22,674 epoch 2 - iter 25/254 - loss 7.04477215 - samples/sec: 241.97 - lr: 0.100000\n",
            "2020-10-27 17:10:25,775 epoch 2 - iter 50/254 - loss 6.79322985 - samples/sec: 258.17 - lr: 0.100000\n",
            "2020-10-27 17:10:28,980 epoch 2 - iter 75/254 - loss 6.61045863 - samples/sec: 249.87 - lr: 0.100000\n",
            "2020-10-27 17:10:32,306 epoch 2 - iter 100/254 - loss 6.56963720 - samples/sec: 240.84 - lr: 0.100000\n",
            "2020-10-27 17:10:35,377 epoch 2 - iter 125/254 - loss 6.41518002 - samples/sec: 260.77 - lr: 0.100000\n",
            "2020-10-27 17:10:38,439 epoch 2 - iter 150/254 - loss 6.29386202 - samples/sec: 261.46 - lr: 0.100000\n",
            "2020-10-27 17:10:41,649 epoch 2 - iter 175/254 - loss 6.18318342 - samples/sec: 249.49 - lr: 0.100000\n",
            "2020-10-27 17:10:44,878 epoch 2 - iter 200/254 - loss 6.12745024 - samples/sec: 247.96 - lr: 0.100000\n",
            "2020-10-27 17:10:48,226 epoch 2 - iter 225/254 - loss 6.04741149 - samples/sec: 239.15 - lr: 0.100000\n",
            "2020-10-27 17:10:51,404 epoch 2 - iter 250/254 - loss 5.98269950 - samples/sec: 252.08 - lr: 0.100000\n",
            "2020-10-27 17:10:51,843 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:10:51,845 EPOCH 2 done: loss 5.9828 - lr 0.1000000\n",
            "2020-10-27 17:10:53,689 DEV : loss 4.080484390258789 - score 0.8062\n",
            "2020-10-27 17:10:53,737 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:10:56,624 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:11:00,018 epoch 3 - iter 25/254 - loss 4.63793627 - samples/sec: 235.97 - lr: 0.100000\n",
            "2020-10-27 17:11:03,067 epoch 3 - iter 50/254 - loss 4.66636662 - samples/sec: 262.70 - lr: 0.100000\n",
            "2020-10-27 17:11:06,150 epoch 3 - iter 75/254 - loss 4.64476214 - samples/sec: 259.69 - lr: 0.100000\n",
            "2020-10-27 17:11:09,340 epoch 3 - iter 100/254 - loss 4.66614139 - samples/sec: 251.24 - lr: 0.100000\n",
            "2020-10-27 17:11:12,778 epoch 3 - iter 125/254 - loss 4.69107880 - samples/sec: 232.84 - lr: 0.100000\n",
            "2020-10-27 17:11:15,935 epoch 3 - iter 150/254 - loss 4.73784072 - samples/sec: 253.63 - lr: 0.100000\n",
            "2020-10-27 17:11:19,196 epoch 3 - iter 175/254 - loss 4.76474470 - samples/sec: 245.67 - lr: 0.100000\n",
            "2020-10-27 17:11:22,479 epoch 3 - iter 200/254 - loss 4.78488378 - samples/sec: 243.92 - lr: 0.100000\n",
            "2020-10-27 17:11:25,710 epoch 3 - iter 225/254 - loss 4.77203099 - samples/sec: 247.82 - lr: 0.100000\n",
            "2020-10-27 17:11:28,954 epoch 3 - iter 250/254 - loss 4.75101877 - samples/sec: 246.95 - lr: 0.100000\n",
            "2020-10-27 17:11:29,365 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:11:29,367 EPOCH 3 done: loss 4.7324 - lr 0.1000000\n",
            "2020-10-27 17:11:31,152 DEV : loss 3.3933682441711426 - score 0.8316\n",
            "2020-10-27 17:11:31,198 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:11:34,078 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:11:37,418 epoch 4 - iter 25/254 - loss 4.41171128 - samples/sec: 240.19 - lr: 0.100000\n",
            "2020-10-27 17:11:40,615 epoch 4 - iter 50/254 - loss 4.22871572 - samples/sec: 250.47 - lr: 0.100000\n",
            "2020-10-27 17:11:43,754 epoch 4 - iter 75/254 - loss 4.39623804 - samples/sec: 255.20 - lr: 0.100000\n",
            "2020-10-27 17:11:46,992 epoch 4 - iter 100/254 - loss 4.34044660 - samples/sec: 247.30 - lr: 0.100000\n",
            "2020-10-27 17:11:50,258 epoch 4 - iter 125/254 - loss 4.25670243 - samples/sec: 245.13 - lr: 0.100000\n",
            "2020-10-27 17:11:53,327 epoch 4 - iter 150/254 - loss 4.21198674 - samples/sec: 260.92 - lr: 0.100000\n",
            "2020-10-27 17:11:56,334 epoch 4 - iter 175/254 - loss 4.12795611 - samples/sec: 266.29 - lr: 0.100000\n",
            "2020-10-27 17:11:59,644 epoch 4 - iter 200/254 - loss 4.12030471 - samples/sec: 241.95 - lr: 0.100000\n",
            "2020-10-27 17:12:02,810 epoch 4 - iter 225/254 - loss 4.11267908 - samples/sec: 253.05 - lr: 0.100000\n",
            "2020-10-27 17:12:05,982 epoch 4 - iter 250/254 - loss 4.10868533 - samples/sec: 252.43 - lr: 0.100000\n",
            "2020-10-27 17:12:06,424 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:12:06,426 EPOCH 4 done: loss 4.1070 - lr 0.1000000\n",
            "2020-10-27 17:12:08,183 DEV : loss 3.063971757888794 - score 0.847\n",
            "2020-10-27 17:12:08,238 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:12:11,007 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:12:14,347 epoch 5 - iter 25/254 - loss 3.54933843 - samples/sec: 239.82 - lr: 0.100000\n",
            "2020-10-27 17:12:17,617 epoch 5 - iter 50/254 - loss 3.70414477 - samples/sec: 244.86 - lr: 0.100000\n",
            "2020-10-27 17:12:21,090 epoch 5 - iter 75/254 - loss 3.79630562 - samples/sec: 230.63 - lr: 0.100000\n",
            "2020-10-27 17:12:24,313 epoch 5 - iter 100/254 - loss 3.86562539 - samples/sec: 248.45 - lr: 0.100000\n",
            "2020-10-27 17:12:27,375 epoch 5 - iter 125/254 - loss 3.77137412 - samples/sec: 261.49 - lr: 0.100000\n",
            "2020-10-27 17:12:30,514 epoch 5 - iter 150/254 - loss 3.73738589 - samples/sec: 255.29 - lr: 0.100000\n",
            "2020-10-27 17:12:33,760 epoch 5 - iter 175/254 - loss 3.71735973 - samples/sec: 246.69 - lr: 0.100000\n",
            "2020-10-27 17:12:36,872 epoch 5 - iter 200/254 - loss 3.67058702 - samples/sec: 257.33 - lr: 0.100000\n",
            "2020-10-27 17:12:40,075 epoch 5 - iter 225/254 - loss 3.67157914 - samples/sec: 249.92 - lr: 0.100000\n",
            "2020-10-27 17:12:43,091 epoch 5 - iter 250/254 - loss 3.62974870 - samples/sec: 265.53 - lr: 0.100000\n",
            "2020-10-27 17:12:43,535 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:12:43,536 EPOCH 5 done: loss 3.6236 - lr 0.1000000\n",
            "2020-10-27 17:12:45,362 DEV : loss 2.8310115337371826 - score 0.858\n",
            "2020-10-27 17:12:45,411 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:12:48,315 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:12:51,602 epoch 6 - iter 25/254 - loss 3.03026165 - samples/sec: 243.67 - lr: 0.100000\n",
            "2020-10-27 17:12:55,347 epoch 6 - iter 50/254 - loss 3.34659172 - samples/sec: 213.91 - lr: 0.100000\n",
            "2020-10-27 17:12:58,281 epoch 6 - iter 75/254 - loss 3.29068780 - samples/sec: 273.09 - lr: 0.100000\n",
            "2020-10-27 17:13:01,639 epoch 6 - iter 100/254 - loss 3.38412168 - samples/sec: 238.48 - lr: 0.100000\n",
            "2020-10-27 17:13:04,881 epoch 6 - iter 125/254 - loss 3.41614263 - samples/sec: 247.00 - lr: 0.100000\n",
            "2020-10-27 17:13:07,935 epoch 6 - iter 150/254 - loss 3.39627786 - samples/sec: 262.25 - lr: 0.100000\n",
            "2020-10-27 17:13:11,050 epoch 6 - iter 175/254 - loss 3.34410481 - samples/sec: 257.05 - lr: 0.100000\n",
            "2020-10-27 17:13:14,222 epoch 6 - iter 200/254 - loss 3.34386607 - samples/sec: 252.39 - lr: 0.100000\n",
            "2020-10-27 17:13:17,417 epoch 6 - iter 225/254 - loss 3.32059300 - samples/sec: 250.67 - lr: 0.100000\n",
            "2020-10-27 17:13:20,431 epoch 6 - iter 250/254 - loss 3.29816102 - samples/sec: 265.91 - lr: 0.100000\n",
            "2020-10-27 17:13:20,906 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:13:20,907 EPOCH 6 done: loss 3.3171 - lr 0.1000000\n",
            "2020-10-27 17:13:22,753 DEV : loss 2.7357428073883057 - score 0.8553\n",
            "2020-10-27 17:13:22,799 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:13:22,800 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:13:26,065 epoch 7 - iter 25/254 - loss 3.20823169 - samples/sec: 245.35 - lr: 0.100000\n",
            "2020-10-27 17:13:29,165 epoch 7 - iter 50/254 - loss 3.17285336 - samples/sec: 258.30 - lr: 0.100000\n",
            "2020-10-27 17:13:32,318 epoch 7 - iter 75/254 - loss 3.17370311 - samples/sec: 253.95 - lr: 0.100000\n",
            "2020-10-27 17:13:35,557 epoch 7 - iter 100/254 - loss 3.12996010 - samples/sec: 247.16 - lr: 0.100000\n",
            "2020-10-27 17:13:38,741 epoch 7 - iter 125/254 - loss 3.09652301 - samples/sec: 251.53 - lr: 0.100000\n",
            "2020-10-27 17:13:41,929 epoch 7 - iter 150/254 - loss 3.07866530 - samples/sec: 251.18 - lr: 0.100000\n",
            "2020-10-27 17:13:45,085 epoch 7 - iter 175/254 - loss 3.05683987 - samples/sec: 253.67 - lr: 0.100000\n",
            "2020-10-27 17:13:48,422 epoch 7 - iter 200/254 - loss 3.06748936 - samples/sec: 239.98 - lr: 0.100000\n",
            "2020-10-27 17:13:51,636 epoch 7 - iter 225/254 - loss 3.07454444 - samples/sec: 249.20 - lr: 0.100000\n",
            "2020-10-27 17:13:55,019 epoch 7 - iter 250/254 - loss 3.06584288 - samples/sec: 236.70 - lr: 0.100000\n",
            "2020-10-27 17:13:55,491 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:13:55,492 EPOCH 7 done: loss 3.0709 - lr 0.1000000\n",
            "2020-10-27 17:13:57,338 DEV : loss 2.4002184867858887 - score 0.875\n",
            "2020-10-27 17:13:57,385 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:14:00,554 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:14:03,882 epoch 8 - iter 25/254 - loss 2.85903721 - samples/sec: 240.67 - lr: 0.100000\n",
            "2020-10-27 17:14:07,240 epoch 8 - iter 50/254 - loss 2.90936949 - samples/sec: 238.47 - lr: 0.100000\n",
            "2020-10-27 17:14:10,292 epoch 8 - iter 75/254 - loss 2.87290597 - samples/sec: 262.38 - lr: 0.100000\n",
            "2020-10-27 17:14:13,349 epoch 8 - iter 100/254 - loss 2.85394979 - samples/sec: 261.89 - lr: 0.100000\n",
            "2020-10-27 17:14:16,465 epoch 8 - iter 125/254 - loss 2.88814712 - samples/sec: 257.17 - lr: 0.100000\n",
            "2020-10-27 17:14:19,813 epoch 8 - iter 150/254 - loss 2.87092241 - samples/sec: 239.20 - lr: 0.100000\n",
            "2020-10-27 17:14:23,036 epoch 8 - iter 175/254 - loss 2.88591571 - samples/sec: 248.43 - lr: 0.100000\n",
            "2020-10-27 17:14:26,280 epoch 8 - iter 200/254 - loss 2.87215365 - samples/sec: 246.80 - lr: 0.100000\n",
            "2020-10-27 17:14:29,369 epoch 8 - iter 225/254 - loss 2.85067860 - samples/sec: 259.19 - lr: 0.100000\n",
            "2020-10-27 17:14:32,657 epoch 8 - iter 250/254 - loss 2.86443414 - samples/sec: 243.57 - lr: 0.100000\n",
            "2020-10-27 17:14:33,025 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:14:33,026 EPOCH 8 done: loss 2.8658 - lr 0.1000000\n",
            "2020-10-27 17:14:34,820 DEV : loss 2.4102425575256348 - score 0.877\n",
            "2020-10-27 17:14:34,868 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:14:37,837 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:14:41,055 epoch 9 - iter 25/254 - loss 2.48271631 - samples/sec: 248.89 - lr: 0.100000\n",
            "2020-10-27 17:14:44,776 epoch 9 - iter 50/254 - loss 2.58137742 - samples/sec: 215.17 - lr: 0.100000\n",
            "2020-10-27 17:14:47,999 epoch 9 - iter 75/254 - loss 2.64047828 - samples/sec: 248.43 - lr: 0.100000\n",
            "2020-10-27 17:14:51,261 epoch 9 - iter 100/254 - loss 2.65909896 - samples/sec: 245.52 - lr: 0.100000\n",
            "2020-10-27 17:14:54,494 epoch 9 - iter 125/254 - loss 2.67992877 - samples/sec: 247.66 - lr: 0.100000\n",
            "2020-10-27 17:14:57,726 epoch 9 - iter 150/254 - loss 2.69514517 - samples/sec: 247.77 - lr: 0.100000\n",
            "2020-10-27 17:15:00,799 epoch 9 - iter 175/254 - loss 2.66098230 - samples/sec: 260.56 - lr: 0.100000\n",
            "2020-10-27 17:15:04,128 epoch 9 - iter 200/254 - loss 2.67605875 - samples/sec: 240.60 - lr: 0.100000\n",
            "2020-10-27 17:15:07,352 epoch 9 - iter 225/254 - loss 2.68842016 - samples/sec: 248.34 - lr: 0.100000\n",
            "2020-10-27 17:15:10,396 epoch 9 - iter 250/254 - loss 2.68209719 - samples/sec: 263.20 - lr: 0.100000\n",
            "2020-10-27 17:15:10,816 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:15:10,817 EPOCH 9 done: loss 2.6737 - lr 0.1000000\n",
            "2020-10-27 17:15:12,609 DEV : loss 2.4524059295654297 - score 0.8745\n",
            "2020-10-27 17:15:12,655 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:15:12,656 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:15:16,011 epoch 10 - iter 25/254 - loss 2.49505337 - samples/sec: 238.81 - lr: 0.100000\n",
            "2020-10-27 17:15:19,175 epoch 10 - iter 50/254 - loss 2.54783216 - samples/sec: 253.02 - lr: 0.100000\n",
            "2020-10-27 17:15:22,236 epoch 10 - iter 75/254 - loss 2.51767958 - samples/sec: 261.62 - lr: 0.100000\n",
            "2020-10-27 17:15:25,465 epoch 10 - iter 100/254 - loss 2.49915991 - samples/sec: 248.01 - lr: 0.100000\n",
            "2020-10-27 17:15:28,664 epoch 10 - iter 125/254 - loss 2.53431011 - samples/sec: 250.28 - lr: 0.100000\n",
            "2020-10-27 17:15:31,945 epoch 10 - iter 150/254 - loss 2.52690839 - samples/sec: 244.02 - lr: 0.100000\n",
            "2020-10-27 17:15:35,052 epoch 10 - iter 175/254 - loss 2.52055592 - samples/sec: 257.86 - lr: 0.100000\n",
            "2020-10-27 17:15:38,302 epoch 10 - iter 200/254 - loss 2.50531334 - samples/sec: 246.42 - lr: 0.100000\n",
            "2020-10-27 17:15:41,593 epoch 10 - iter 225/254 - loss 2.52578701 - samples/sec: 243.28 - lr: 0.100000\n",
            "2020-10-27 17:15:44,708 epoch 10 - iter 250/254 - loss 2.51725225 - samples/sec: 257.04 - lr: 0.100000\n",
            "2020-10-27 17:15:45,107 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:15:45,108 EPOCH 10 done: loss 2.5164 - lr 0.1000000\n",
            "2020-10-27 17:15:46,901 DEV : loss 2.1729090213775635 - score 0.8866\n",
            "2020-10-27 17:15:46,948 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:15:49,905 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:15:53,385 epoch 11 - iter 25/254 - loss 2.17056185 - samples/sec: 230.16 - lr: 0.100000\n",
            "2020-10-27 17:15:56,503 epoch 11 - iter 50/254 - loss 2.25193786 - samples/sec: 256.83 - lr: 0.100000\n",
            "2020-10-27 17:15:59,744 epoch 11 - iter 75/254 - loss 2.31778849 - samples/sec: 247.15 - lr: 0.100000\n",
            "2020-10-27 17:16:02,791 epoch 11 - iter 100/254 - loss 2.30538687 - samples/sec: 262.80 - lr: 0.100000\n",
            "2020-10-27 17:16:05,867 epoch 11 - iter 125/254 - loss 2.31289754 - samples/sec: 260.37 - lr: 0.100000\n",
            "2020-10-27 17:16:09,185 epoch 11 - iter 150/254 - loss 2.33170277 - samples/sec: 241.44 - lr: 0.100000\n",
            "2020-10-27 17:16:12,445 epoch 11 - iter 175/254 - loss 2.35787040 - samples/sec: 245.59 - lr: 0.100000\n",
            "2020-10-27 17:16:15,716 epoch 11 - iter 200/254 - loss 2.40222851 - samples/sec: 244.77 - lr: 0.100000\n",
            "2020-10-27 17:16:19,143 epoch 11 - iter 225/254 - loss 2.39724676 - samples/sec: 233.68 - lr: 0.100000\n",
            "2020-10-27 17:16:22,348 epoch 11 - iter 250/254 - loss 2.39186964 - samples/sec: 249.80 - lr: 0.100000\n",
            "2020-10-27 17:16:22,763 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:16:22,764 EPOCH 11 done: loss 2.3891 - lr 0.1000000\n",
            "2020-10-27 17:16:24,622 DEV : loss 2.260093927383423 - score 0.8797\n",
            "2020-10-27 17:16:24,669 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:16:24,670 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:16:27,920 epoch 12 - iter 25/254 - loss 2.05722247 - samples/sec: 246.51 - lr: 0.100000\n",
            "2020-10-27 17:16:31,401 epoch 12 - iter 50/254 - loss 2.20559731 - samples/sec: 230.07 - lr: 0.100000\n",
            "2020-10-27 17:16:34,414 epoch 12 - iter 75/254 - loss 2.21280847 - samples/sec: 265.93 - lr: 0.100000\n",
            "2020-10-27 17:16:37,514 epoch 12 - iter 100/254 - loss 2.17264447 - samples/sec: 258.34 - lr: 0.100000\n",
            "2020-10-27 17:16:40,762 epoch 12 - iter 125/254 - loss 2.22874009 - samples/sec: 246.47 - lr: 0.100000\n",
            "2020-10-27 17:16:43,713 epoch 12 - iter 150/254 - loss 2.19503641 - samples/sec: 271.41 - lr: 0.100000\n",
            "2020-10-27 17:16:47,071 epoch 12 - iter 175/254 - loss 2.22316428 - samples/sec: 238.41 - lr: 0.100000\n",
            "2020-10-27 17:16:50,307 epoch 12 - iter 200/254 - loss 2.23677612 - samples/sec: 247.42 - lr: 0.100000\n",
            "2020-10-27 17:16:53,532 epoch 12 - iter 225/254 - loss 2.22764319 - samples/sec: 248.29 - lr: 0.100000\n",
            "2020-10-27 17:16:56,565 epoch 12 - iter 250/254 - loss 2.22607044 - samples/sec: 264.00 - lr: 0.100000\n",
            "2020-10-27 17:16:56,974 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:16:56,975 EPOCH 12 done: loss 2.2189 - lr 0.1000000\n",
            "2020-10-27 17:16:58,787 DEV : loss 2.155740976333618 - score 0.8904\n",
            "2020-10-27 17:16:58,835 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:17:01,798 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:17:05,222 epoch 13 - iter 25/254 - loss 2.23385984 - samples/sec: 234.19 - lr: 0.100000\n",
            "2020-10-27 17:17:08,322 epoch 13 - iter 50/254 - loss 2.17883966 - samples/sec: 258.25 - lr: 0.100000\n",
            "2020-10-27 17:17:11,433 epoch 13 - iter 75/254 - loss 2.18490938 - samples/sec: 257.38 - lr: 0.100000\n",
            "2020-10-27 17:17:14,820 epoch 13 - iter 100/254 - loss 2.21860314 - samples/sec: 236.42 - lr: 0.100000\n",
            "2020-10-27 17:17:17,870 epoch 13 - iter 125/254 - loss 2.15755728 - samples/sec: 262.52 - lr: 0.100000\n",
            "2020-10-27 17:17:20,909 epoch 13 - iter 150/254 - loss 2.14602724 - samples/sec: 263.45 - lr: 0.100000\n",
            "2020-10-27 17:17:24,237 epoch 13 - iter 175/254 - loss 2.15766755 - samples/sec: 240.61 - lr: 0.100000\n",
            "2020-10-27 17:17:27,597 epoch 13 - iter 200/254 - loss 2.17691121 - samples/sec: 238.30 - lr: 0.100000\n",
            "2020-10-27 17:17:30,735 epoch 13 - iter 225/254 - loss 2.14975080 - samples/sec: 255.18 - lr: 0.100000\n",
            "2020-10-27 17:17:33,993 epoch 13 - iter 250/254 - loss 2.14078577 - samples/sec: 245.90 - lr: 0.100000\n",
            "2020-10-27 17:17:34,400 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:17:34,402 EPOCH 13 done: loss 2.1339 - lr 0.1000000\n",
            "2020-10-27 17:17:36,231 DEV : loss 2.0907511711120605 - score 0.8971\n",
            "2020-10-27 17:17:36,280 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:17:39,234 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:17:42,601 epoch 14 - iter 25/254 - loss 1.87011278 - samples/sec: 237.92 - lr: 0.100000\n",
            "2020-10-27 17:17:45,786 epoch 14 - iter 50/254 - loss 1.91787405 - samples/sec: 251.39 - lr: 0.100000\n",
            "2020-10-27 17:17:48,948 epoch 14 - iter 75/254 - loss 1.91000269 - samples/sec: 253.21 - lr: 0.100000\n",
            "2020-10-27 17:17:52,057 epoch 14 - iter 100/254 - loss 1.98744425 - samples/sec: 257.71 - lr: 0.100000\n",
            "2020-10-27 17:17:55,265 epoch 14 - iter 125/254 - loss 1.98526425 - samples/sec: 249.56 - lr: 0.100000\n",
            "2020-10-27 17:17:58,500 epoch 14 - iter 150/254 - loss 1.98716374 - samples/sec: 247.51 - lr: 0.100000\n",
            "2020-10-27 17:18:01,775 epoch 14 - iter 175/254 - loss 2.01241784 - samples/sec: 244.66 - lr: 0.100000\n",
            "2020-10-27 17:18:05,083 epoch 14 - iter 200/254 - loss 2.03121012 - samples/sec: 242.09 - lr: 0.100000\n",
            "2020-10-27 17:18:08,548 epoch 14 - iter 225/254 - loss 2.02735031 - samples/sec: 231.06 - lr: 0.100000\n",
            "2020-10-27 17:18:11,554 epoch 14 - iter 250/254 - loss 2.03008860 - samples/sec: 266.36 - lr: 0.100000\n",
            "2020-10-27 17:18:12,014 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:18:12,015 EPOCH 14 done: loss 2.0357 - lr 0.1000000\n",
            "2020-10-27 17:18:13,781 DEV : loss 2.072341203689575 - score 0.8936\n",
            "2020-10-27 17:18:13,832 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:18:13,833 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:18:17,115 epoch 15 - iter 25/254 - loss 1.97293209 - samples/sec: 244.15 - lr: 0.100000\n",
            "2020-10-27 17:18:20,038 epoch 15 - iter 50/254 - loss 1.90780783 - samples/sec: 274.09 - lr: 0.100000\n",
            "2020-10-27 17:18:23,255 epoch 15 - iter 75/254 - loss 1.91747186 - samples/sec: 249.12 - lr: 0.100000\n",
            "2020-10-27 17:18:26,369 epoch 15 - iter 100/254 - loss 1.93630760 - samples/sec: 257.11 - lr: 0.100000\n",
            "2020-10-27 17:18:29,775 epoch 15 - iter 125/254 - loss 1.94562869 - samples/sec: 235.08 - lr: 0.100000\n",
            "2020-10-27 17:18:33,017 epoch 15 - iter 150/254 - loss 1.93917460 - samples/sec: 247.03 - lr: 0.100000\n",
            "2020-10-27 17:18:36,189 epoch 15 - iter 175/254 - loss 1.92939437 - samples/sec: 252.37 - lr: 0.100000\n",
            "2020-10-27 17:18:39,454 epoch 15 - iter 200/254 - loss 1.93058904 - samples/sec: 245.29 - lr: 0.100000\n",
            "2020-10-27 17:18:42,597 epoch 15 - iter 225/254 - loss 1.92205858 - samples/sec: 254.74 - lr: 0.100000\n",
            "2020-10-27 17:18:45,775 epoch 15 - iter 250/254 - loss 1.93492082 - samples/sec: 251.93 - lr: 0.100000\n",
            "2020-10-27 17:18:46,235 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:18:46,237 EPOCH 15 done: loss 1.9342 - lr 0.1000000\n",
            "2020-10-27 17:18:48,046 DEV : loss 2.0636537075042725 - score 0.8949\n",
            "2020-10-27 17:18:48,107 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:18:48,108 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:18:51,341 epoch 16 - iter 25/254 - loss 1.95688855 - samples/sec: 247.79 - lr: 0.100000\n",
            "2020-10-27 17:18:54,629 epoch 16 - iter 50/254 - loss 1.94292768 - samples/sec: 243.46 - lr: 0.100000\n",
            "2020-10-27 17:18:57,767 epoch 16 - iter 75/254 - loss 1.91309828 - samples/sec: 255.18 - lr: 0.100000\n",
            "2020-10-27 17:19:01,195 epoch 16 - iter 100/254 - loss 1.90100847 - samples/sec: 233.57 - lr: 0.100000\n",
            "2020-10-27 17:19:04,490 epoch 16 - iter 125/254 - loss 1.86855631 - samples/sec: 243.08 - lr: 0.100000\n",
            "2020-10-27 17:19:07,719 epoch 16 - iter 150/254 - loss 1.86204742 - samples/sec: 247.93 - lr: 0.100000\n",
            "2020-10-27 17:19:11,072 epoch 16 - iter 175/254 - loss 1.87590464 - samples/sec: 238.85 - lr: 0.100000\n",
            "2020-10-27 17:19:14,599 epoch 16 - iter 200/254 - loss 1.89774164 - samples/sec: 227.12 - lr: 0.100000\n",
            "2020-10-27 17:19:17,742 epoch 16 - iter 225/254 - loss 1.87664882 - samples/sec: 254.74 - lr: 0.100000\n",
            "2020-10-27 17:19:20,734 epoch 16 - iter 250/254 - loss 1.86084853 - samples/sec: 267.62 - lr: 0.100000\n",
            "2020-10-27 17:19:21,116 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:19:21,117 EPOCH 16 done: loss 1.8624 - lr 0.1000000\n",
            "2020-10-27 17:19:22,932 DEV : loss 2.0752480030059814 - score 0.8947\n",
            "2020-10-27 17:19:22,981 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:19:22,982 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:19:26,111 epoch 17 - iter 25/254 - loss 1.54342381 - samples/sec: 256.02 - lr: 0.100000\n",
            "2020-10-27 17:19:29,574 epoch 17 - iter 50/254 - loss 1.68086133 - samples/sec: 231.20 - lr: 0.100000\n",
            "2020-10-27 17:19:32,598 epoch 17 - iter 75/254 - loss 1.68733099 - samples/sec: 264.87 - lr: 0.100000\n",
            "2020-10-27 17:19:35,869 epoch 17 - iter 100/254 - loss 1.69740193 - samples/sec: 244.81 - lr: 0.100000\n",
            "2020-10-27 17:19:39,166 epoch 17 - iter 125/254 - loss 1.71962999 - samples/sec: 242.79 - lr: 0.100000\n",
            "2020-10-27 17:19:42,343 epoch 17 - iter 150/254 - loss 1.71916907 - samples/sec: 252.09 - lr: 0.100000\n",
            "2020-10-27 17:19:45,494 epoch 17 - iter 175/254 - loss 1.70137267 - samples/sec: 254.12 - lr: 0.100000\n",
            "2020-10-27 17:19:48,505 epoch 17 - iter 200/254 - loss 1.70945972 - samples/sec: 265.89 - lr: 0.100000\n",
            "2020-10-27 17:19:51,646 epoch 17 - iter 225/254 - loss 1.72242558 - samples/sec: 254.91 - lr: 0.100000\n",
            "2020-10-27 17:19:55,251 epoch 17 - iter 250/254 - loss 1.75140752 - samples/sec: 222.15 - lr: 0.100000\n",
            "2020-10-27 17:19:55,638 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:19:55,640 EPOCH 17 done: loss 1.7473 - lr 0.1000000\n",
            "2020-10-27 17:19:57,860 DEV : loss 2.053154230117798 - score 0.896\n",
            "Epoch    17: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-10-27 17:19:57,915 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:19:57,917 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:20:01,156 epoch 18 - iter 25/254 - loss 1.58325583 - samples/sec: 247.34 - lr: 0.050000\n",
            "2020-10-27 17:20:04,427 epoch 18 - iter 50/254 - loss 1.51336835 - samples/sec: 244.80 - lr: 0.050000\n",
            "2020-10-27 17:20:07,574 epoch 18 - iter 75/254 - loss 1.47052587 - samples/sec: 254.48 - lr: 0.050000\n",
            "2020-10-27 17:20:10,717 epoch 18 - iter 100/254 - loss 1.50608097 - samples/sec: 255.05 - lr: 0.050000\n",
            "2020-10-27 17:20:13,960 epoch 18 - iter 125/254 - loss 1.51196329 - samples/sec: 246.87 - lr: 0.050000\n",
            "2020-10-27 17:20:17,226 epoch 18 - iter 150/254 - loss 1.53944573 - samples/sec: 245.16 - lr: 0.050000\n",
            "2020-10-27 17:20:20,534 epoch 18 - iter 175/254 - loss 1.55911703 - samples/sec: 242.05 - lr: 0.050000\n",
            "2020-10-27 17:20:23,748 epoch 18 - iter 200/254 - loss 1.55204914 - samples/sec: 249.18 - lr: 0.050000\n",
            "2020-10-27 17:20:27,230 epoch 18 - iter 225/254 - loss 1.54175743 - samples/sec: 229.89 - lr: 0.050000\n",
            "2020-10-27 17:20:30,466 epoch 18 - iter 250/254 - loss 1.56219380 - samples/sec: 247.49 - lr: 0.050000\n",
            "2020-10-27 17:20:30,892 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:20:30,893 EPOCH 18 done: loss 1.5584 - lr 0.0500000\n",
            "2020-10-27 17:20:32,744 DEV : loss 2.003392457962036 - score 0.9037\n",
            "2020-10-27 17:20:32,789 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:20:35,693 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:20:39,147 epoch 19 - iter 25/254 - loss 1.44161955 - samples/sec: 231.88 - lr: 0.050000\n",
            "2020-10-27 17:20:42,367 epoch 19 - iter 50/254 - loss 1.43460336 - samples/sec: 248.75 - lr: 0.050000\n",
            "2020-10-27 17:20:45,689 epoch 19 - iter 75/254 - loss 1.47965022 - samples/sec: 241.00 - lr: 0.050000\n",
            "2020-10-27 17:20:48,879 epoch 19 - iter 100/254 - loss 1.47633219 - samples/sec: 251.17 - lr: 0.050000\n",
            "2020-10-27 17:20:51,979 epoch 19 - iter 125/254 - loss 1.45035200 - samples/sec: 258.27 - lr: 0.050000\n",
            "2020-10-27 17:20:55,145 epoch 19 - iter 150/254 - loss 1.45712509 - samples/sec: 252.95 - lr: 0.050000\n",
            "2020-10-27 17:20:58,102 epoch 19 - iter 175/254 - loss 1.45247727 - samples/sec: 270.74 - lr: 0.050000\n",
            "2020-10-27 17:21:01,718 epoch 19 - iter 200/254 - loss 1.47124652 - samples/sec: 221.42 - lr: 0.050000\n",
            "2020-10-27 17:21:04,764 epoch 19 - iter 225/254 - loss 1.47271862 - samples/sec: 262.87 - lr: 0.050000\n",
            "2020-10-27 17:21:08,012 epoch 19 - iter 250/254 - loss 1.48824463 - samples/sec: 246.66 - lr: 0.050000\n",
            "2020-10-27 17:21:08,457 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:21:08,458 EPOCH 19 done: loss 1.4828 - lr 0.0500000\n",
            "2020-10-27 17:21:10,277 DEV : loss 2.009709119796753 - score 0.899\n",
            "2020-10-27 17:21:10,324 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:21:10,325 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:21:13,593 epoch 20 - iter 25/254 - loss 1.33418674 - samples/sec: 245.15 - lr: 0.050000\n",
            "2020-10-27 17:21:16,797 epoch 20 - iter 50/254 - loss 1.38924695 - samples/sec: 249.94 - lr: 0.050000\n",
            "2020-10-27 17:21:19,978 epoch 20 - iter 75/254 - loss 1.38164699 - samples/sec: 251.71 - lr: 0.050000\n",
            "2020-10-27 17:21:23,338 epoch 20 - iter 100/254 - loss 1.40912329 - samples/sec: 238.30 - lr: 0.050000\n",
            "2020-10-27 17:21:26,649 epoch 20 - iter 125/254 - loss 1.44884262 - samples/sec: 242.13 - lr: 0.050000\n",
            "2020-10-27 17:21:29,822 epoch 20 - iter 150/254 - loss 1.44436412 - samples/sec: 252.38 - lr: 0.050000\n",
            "2020-10-27 17:21:33,320 epoch 20 - iter 175/254 - loss 1.44140230 - samples/sec: 228.92 - lr: 0.050000\n",
            "2020-10-27 17:21:36,497 epoch 20 - iter 200/254 - loss 1.44862687 - samples/sec: 252.00 - lr: 0.050000\n",
            "2020-10-27 17:21:39,761 epoch 20 - iter 225/254 - loss 1.44217765 - samples/sec: 245.30 - lr: 0.050000\n",
            "2020-10-27 17:21:42,761 epoch 20 - iter 250/254 - loss 1.42982407 - samples/sec: 266.98 - lr: 0.050000\n",
            "2020-10-27 17:21:43,271 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:21:43,272 EPOCH 20 done: loss 1.4307 - lr 0.0500000\n",
            "2020-10-27 17:21:45,133 DEV : loss 1.9953813552856445 - score 0.903\n",
            "2020-10-27 17:21:45,180 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:21:45,181 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:21:48,352 epoch 21 - iter 25/254 - loss 1.30808320 - samples/sec: 252.54 - lr: 0.050000\n",
            "2020-10-27 17:21:51,577 epoch 21 - iter 50/254 - loss 1.32972663 - samples/sec: 248.35 - lr: 0.050000\n",
            "2020-10-27 17:21:54,766 epoch 21 - iter 75/254 - loss 1.33921285 - samples/sec: 251.05 - lr: 0.050000\n",
            "2020-10-27 17:21:58,100 epoch 21 - iter 100/254 - loss 1.36876541 - samples/sec: 240.20 - lr: 0.050000\n",
            "2020-10-27 17:22:01,361 epoch 21 - iter 125/254 - loss 1.37669205 - samples/sec: 245.51 - lr: 0.050000\n",
            "2020-10-27 17:22:04,666 epoch 21 - iter 150/254 - loss 1.38842557 - samples/sec: 242.39 - lr: 0.050000\n",
            "2020-10-27 17:22:07,750 epoch 21 - iter 175/254 - loss 1.36693887 - samples/sec: 259.59 - lr: 0.050000\n",
            "2020-10-27 17:22:10,984 epoch 21 - iter 200/254 - loss 1.36821734 - samples/sec: 247.73 - lr: 0.050000\n",
            "2020-10-27 17:22:14,248 epoch 21 - iter 225/254 - loss 1.36560186 - samples/sec: 245.32 - lr: 0.050000\n",
            "2020-10-27 17:22:17,559 epoch 21 - iter 250/254 - loss 1.36736942 - samples/sec: 241.86 - lr: 0.050000\n",
            "2020-10-27 17:22:17,988 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:22:17,989 EPOCH 21 done: loss 1.3625 - lr 0.0500000\n",
            "2020-10-27 17:22:19,820 DEV : loss 2.0428969860076904 - score 0.9047\n",
            "2020-10-27 17:22:19,865 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:22:23,083 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:22:26,425 epoch 22 - iter 25/254 - loss 1.31718908 - samples/sec: 239.70 - lr: 0.050000\n",
            "2020-10-27 17:22:29,579 epoch 22 - iter 50/254 - loss 1.35098999 - samples/sec: 253.95 - lr: 0.050000\n",
            "2020-10-27 17:22:32,619 epoch 22 - iter 75/254 - loss 1.32271223 - samples/sec: 263.45 - lr: 0.050000\n",
            "2020-10-27 17:22:36,235 epoch 22 - iter 100/254 - loss 1.35031785 - samples/sec: 221.51 - lr: 0.050000\n",
            "2020-10-27 17:22:39,502 epoch 22 - iter 125/254 - loss 1.35743331 - samples/sec: 245.07 - lr: 0.050000\n",
            "2020-10-27 17:22:42,707 epoch 22 - iter 150/254 - loss 1.34715316 - samples/sec: 249.89 - lr: 0.050000\n",
            "2020-10-27 17:22:46,258 epoch 22 - iter 175/254 - loss 1.36832316 - samples/sec: 225.55 - lr: 0.050000\n",
            "2020-10-27 17:22:49,341 epoch 22 - iter 200/254 - loss 1.36373036 - samples/sec: 259.73 - lr: 0.050000\n",
            "2020-10-27 17:22:52,667 epoch 22 - iter 225/254 - loss 1.37134266 - samples/sec: 240.83 - lr: 0.050000\n",
            "2020-10-27 17:22:55,813 epoch 22 - iter 250/254 - loss 1.37260963 - samples/sec: 254.67 - lr: 0.050000\n",
            "2020-10-27 17:22:56,239 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:22:56,240 EPOCH 22 done: loss 1.3821 - lr 0.0500000\n",
            "2020-10-27 17:22:58,124 DEV : loss 1.980286955833435 - score 0.9048\n",
            "2020-10-27 17:22:58,179 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:23:01,068 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:23:04,485 epoch 23 - iter 25/254 - loss 1.27321405 - samples/sec: 234.43 - lr: 0.050000\n",
            "2020-10-27 17:23:07,953 epoch 23 - iter 50/254 - loss 1.26204988 - samples/sec: 230.92 - lr: 0.050000\n",
            "2020-10-27 17:23:11,190 epoch 23 - iter 75/254 - loss 1.30112675 - samples/sec: 247.48 - lr: 0.050000\n",
            "2020-10-27 17:23:14,440 epoch 23 - iter 100/254 - loss 1.28747372 - samples/sec: 246.34 - lr: 0.050000\n",
            "2020-10-27 17:23:17,683 epoch 23 - iter 125/254 - loss 1.28126833 - samples/sec: 246.87 - lr: 0.050000\n",
            "2020-10-27 17:23:20,931 epoch 23 - iter 150/254 - loss 1.28204575 - samples/sec: 246.53 - lr: 0.050000\n",
            "2020-10-27 17:23:24,168 epoch 23 - iter 175/254 - loss 1.27932833 - samples/sec: 247.39 - lr: 0.050000\n",
            "2020-10-27 17:23:27,557 epoch 23 - iter 200/254 - loss 1.29821556 - samples/sec: 236.38 - lr: 0.050000\n",
            "2020-10-27 17:23:30,671 epoch 23 - iter 225/254 - loss 1.29476936 - samples/sec: 257.13 - lr: 0.050000\n",
            "2020-10-27 17:23:33,909 epoch 23 - iter 250/254 - loss 1.30028937 - samples/sec: 247.29 - lr: 0.050000\n",
            "2020-10-27 17:23:34,312 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:23:34,313 EPOCH 23 done: loss 1.3110 - lr 0.0500000\n",
            "2020-10-27 17:23:36,139 DEV : loss 1.9705686569213867 - score 0.9081\n",
            "2020-10-27 17:23:36,185 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:23:39,133 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:23:42,410 epoch 24 - iter 25/254 - loss 1.14404840 - samples/sec: 244.92 - lr: 0.050000\n",
            "2020-10-27 17:23:45,555 epoch 24 - iter 50/254 - loss 1.19997296 - samples/sec: 254.57 - lr: 0.050000\n",
            "2020-10-27 17:23:48,803 epoch 24 - iter 75/254 - loss 1.21239775 - samples/sec: 246.51 - lr: 0.050000\n",
            "2020-10-27 17:23:52,146 epoch 24 - iter 100/254 - loss 1.21706483 - samples/sec: 239.54 - lr: 0.050000\n",
            "2020-10-27 17:23:55,355 epoch 24 - iter 125/254 - loss 1.20932454 - samples/sec: 249.49 - lr: 0.050000\n",
            "2020-10-27 17:23:58,561 epoch 24 - iter 150/254 - loss 1.23895104 - samples/sec: 249.76 - lr: 0.050000\n",
            "2020-10-27 17:24:01,795 epoch 24 - iter 175/254 - loss 1.22556991 - samples/sec: 247.63 - lr: 0.050000\n",
            "2020-10-27 17:24:05,001 epoch 24 - iter 200/254 - loss 1.22847115 - samples/sec: 249.77 - lr: 0.050000\n",
            "2020-10-27 17:24:08,278 epoch 24 - iter 225/254 - loss 1.23785644 - samples/sec: 244.43 - lr: 0.050000\n",
            "2020-10-27 17:24:11,522 epoch 24 - iter 250/254 - loss 1.23070486 - samples/sec: 246.82 - lr: 0.050000\n",
            "2020-10-27 17:24:11,953 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:24:11,954 EPOCH 24 done: loss 1.2352 - lr 0.0500000\n",
            "2020-10-27 17:24:13,821 DEV : loss 1.9890930652618408 - score 0.9052\n",
            "2020-10-27 17:24:13,870 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:24:13,871 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:24:17,270 epoch 25 - iter 25/254 - loss 1.25442955 - samples/sec: 235.82 - lr: 0.050000\n",
            "2020-10-27 17:24:20,498 epoch 25 - iter 50/254 - loss 1.18024593 - samples/sec: 248.21 - lr: 0.050000\n",
            "2020-10-27 17:24:23,782 epoch 25 - iter 75/254 - loss 1.15680561 - samples/sec: 243.92 - lr: 0.050000\n",
            "2020-10-27 17:24:26,997 epoch 25 - iter 100/254 - loss 1.15996335 - samples/sec: 249.11 - lr: 0.050000\n",
            "2020-10-27 17:24:30,129 epoch 25 - iter 125/254 - loss 1.17110209 - samples/sec: 255.67 - lr: 0.050000\n",
            "2020-10-27 17:24:33,331 epoch 25 - iter 150/254 - loss 1.18180392 - samples/sec: 250.13 - lr: 0.050000\n",
            "2020-10-27 17:24:36,418 epoch 25 - iter 175/254 - loss 1.20219114 - samples/sec: 259.40 - lr: 0.050000\n",
            "2020-10-27 17:24:39,673 epoch 25 - iter 200/254 - loss 1.20083670 - samples/sec: 245.99 - lr: 0.050000\n",
            "2020-10-27 17:24:42,762 epoch 25 - iter 225/254 - loss 1.21579002 - samples/sec: 259.29 - lr: 0.050000\n",
            "2020-10-27 17:24:46,234 epoch 25 - iter 250/254 - loss 1.22819605 - samples/sec: 230.58 - lr: 0.050000\n",
            "2020-10-27 17:24:46,680 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:24:46,681 EPOCH 25 done: loss 1.2344 - lr 0.0500000\n",
            "2020-10-27 17:24:48,962 DEV : loss 1.9748477935791016 - score 0.9054\n",
            "2020-10-27 17:24:49,007 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:24:49,009 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:24:52,144 epoch 26 - iter 25/254 - loss 1.10395332 - samples/sec: 255.44 - lr: 0.050000\n",
            "2020-10-27 17:24:55,363 epoch 26 - iter 50/254 - loss 1.14595958 - samples/sec: 248.74 - lr: 0.050000\n",
            "2020-10-27 17:24:58,614 epoch 26 - iter 75/254 - loss 1.18237789 - samples/sec: 246.33 - lr: 0.050000\n",
            "2020-10-27 17:25:01,893 epoch 26 - iter 100/254 - loss 1.14919308 - samples/sec: 244.21 - lr: 0.050000\n",
            "2020-10-27 17:25:05,002 epoch 26 - iter 125/254 - loss 1.13931600 - samples/sec: 257.49 - lr: 0.050000\n",
            "2020-10-27 17:25:08,459 epoch 26 - iter 150/254 - loss 1.15493299 - samples/sec: 231.64 - lr: 0.050000\n",
            "2020-10-27 17:25:11,732 epoch 26 - iter 175/254 - loss 1.15650751 - samples/sec: 244.66 - lr: 0.050000\n",
            "2020-10-27 17:25:14,940 epoch 26 - iter 200/254 - loss 1.16511740 - samples/sec: 249.62 - lr: 0.050000\n",
            "2020-10-27 17:25:18,101 epoch 26 - iter 225/254 - loss 1.17634862 - samples/sec: 253.43 - lr: 0.050000\n",
            "2020-10-27 17:25:21,510 epoch 26 - iter 250/254 - loss 1.18603290 - samples/sec: 234.96 - lr: 0.050000\n",
            "2020-10-27 17:25:21,949 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:25:21,950 EPOCH 26 done: loss 1.1818 - lr 0.0500000\n",
            "2020-10-27 17:25:23,759 DEV : loss 2.018021583557129 - score 0.9084\n",
            "2020-10-27 17:25:23,804 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:25:26,715 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:25:30,051 epoch 27 - iter 25/254 - loss 1.16893675 - samples/sec: 240.11 - lr: 0.050000\n",
            "2020-10-27 17:25:33,112 epoch 27 - iter 50/254 - loss 1.13663197 - samples/sec: 261.58 - lr: 0.050000\n",
            "2020-10-27 17:25:36,501 epoch 27 - iter 75/254 - loss 1.14132686 - samples/sec: 236.24 - lr: 0.050000\n",
            "2020-10-27 17:25:39,768 epoch 27 - iter 100/254 - loss 1.15058689 - samples/sec: 245.09 - lr: 0.050000\n",
            "2020-10-27 17:25:43,058 epoch 27 - iter 125/254 - loss 1.14613016 - samples/sec: 243.46 - lr: 0.050000\n",
            "2020-10-27 17:25:46,401 epoch 27 - iter 150/254 - loss 1.14259108 - samples/sec: 239.52 - lr: 0.050000\n",
            "2020-10-27 17:25:49,534 epoch 27 - iter 175/254 - loss 1.14961270 - samples/sec: 255.57 - lr: 0.050000\n",
            "2020-10-27 17:25:53,027 epoch 27 - iter 200/254 - loss 1.15196922 - samples/sec: 229.23 - lr: 0.050000\n",
            "2020-10-27 17:25:56,269 epoch 27 - iter 225/254 - loss 1.16786600 - samples/sec: 246.96 - lr: 0.050000\n",
            "2020-10-27 17:25:59,417 epoch 27 - iter 250/254 - loss 1.17432209 - samples/sec: 254.36 - lr: 0.050000\n",
            "2020-10-27 17:25:59,853 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:25:59,854 EPOCH 27 done: loss 1.1736 - lr 0.0500000\n",
            "2020-10-27 17:26:01,704 DEV : loss 2.0003604888916016 - score 0.9092\n",
            "2020-10-27 17:26:01,752 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:26:04,737 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:26:08,310 epoch 28 - iter 25/254 - loss 1.14602749 - samples/sec: 224.15 - lr: 0.050000\n",
            "2020-10-27 17:26:11,345 epoch 28 - iter 50/254 - loss 1.16539897 - samples/sec: 263.77 - lr: 0.050000\n",
            "2020-10-27 17:26:14,511 epoch 28 - iter 75/254 - loss 1.15629587 - samples/sec: 253.04 - lr: 0.050000\n",
            "2020-10-27 17:26:17,884 epoch 28 - iter 100/254 - loss 1.19027302 - samples/sec: 237.79 - lr: 0.050000\n",
            "2020-10-27 17:26:21,087 epoch 28 - iter 125/254 - loss 1.17006929 - samples/sec: 249.99 - lr: 0.050000\n",
            "2020-10-27 17:26:24,521 epoch 28 - iter 150/254 - loss 1.14887284 - samples/sec: 233.20 - lr: 0.050000\n",
            "2020-10-27 17:26:27,717 epoch 28 - iter 175/254 - loss 1.14214416 - samples/sec: 250.49 - lr: 0.050000\n",
            "2020-10-27 17:26:30,993 epoch 28 - iter 200/254 - loss 1.14626544 - samples/sec: 244.39 - lr: 0.050000\n",
            "2020-10-27 17:26:34,283 epoch 28 - iter 225/254 - loss 1.14117805 - samples/sec: 243.39 - lr: 0.050000\n",
            "2020-10-27 17:26:37,294 epoch 28 - iter 250/254 - loss 1.13916719 - samples/sec: 265.93 - lr: 0.050000\n",
            "2020-10-27 17:26:37,694 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:26:37,695 EPOCH 28 done: loss 1.1387 - lr 0.0500000\n",
            "2020-10-27 17:26:39,529 DEV : loss 2.056325674057007 - score 0.9047\n",
            "2020-10-27 17:26:39,582 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:26:39,588 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:26:42,771 epoch 29 - iter 25/254 - loss 1.09632965 - samples/sec: 251.57 - lr: 0.050000\n",
            "2020-10-27 17:26:45,854 epoch 29 - iter 50/254 - loss 1.04140493 - samples/sec: 259.72 - lr: 0.050000\n",
            "2020-10-27 17:26:49,454 epoch 29 - iter 75/254 - loss 1.08260975 - samples/sec: 222.46 - lr: 0.050000\n",
            "2020-10-27 17:26:52,780 epoch 29 - iter 100/254 - loss 1.08507962 - samples/sec: 240.68 - lr: 0.050000\n",
            "2020-10-27 17:26:55,746 epoch 29 - iter 125/254 - loss 1.04678430 - samples/sec: 270.20 - lr: 0.050000\n",
            "2020-10-27 17:26:59,090 epoch 29 - iter 150/254 - loss 1.05708294 - samples/sec: 239.43 - lr: 0.050000\n",
            "2020-10-27 17:27:02,375 epoch 29 - iter 175/254 - loss 1.05716996 - samples/sec: 243.75 - lr: 0.050000\n",
            "2020-10-27 17:27:05,592 epoch 29 - iter 200/254 - loss 1.05807607 - samples/sec: 248.89 - lr: 0.050000\n",
            "2020-10-27 17:27:08,798 epoch 29 - iter 225/254 - loss 1.07145081 - samples/sec: 249.72 - lr: 0.050000\n",
            "2020-10-27 17:27:12,074 epoch 29 - iter 250/254 - loss 1.08809108 - samples/sec: 244.53 - lr: 0.050000\n",
            "2020-10-27 17:27:12,455 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:27:12,456 EPOCH 29 done: loss 1.0846 - lr 0.0500000\n",
            "2020-10-27 17:27:14,290 DEV : loss 2.036849021911621 - score 0.91\n",
            "2020-10-27 17:27:14,337 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:27:17,293 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:27:21,188 epoch 30 - iter 25/254 - loss 1.19829313 - samples/sec: 228.92 - lr: 0.050000\n",
            "2020-10-27 17:27:24,258 epoch 30 - iter 50/254 - loss 1.06932320 - samples/sec: 260.88 - lr: 0.050000\n",
            "2020-10-27 17:27:27,505 epoch 30 - iter 75/254 - loss 1.07311840 - samples/sec: 247.04 - lr: 0.050000\n",
            "2020-10-27 17:27:30,605 epoch 30 - iter 100/254 - loss 1.05415148 - samples/sec: 258.28 - lr: 0.050000\n",
            "2020-10-27 17:27:33,796 epoch 30 - iter 125/254 - loss 1.05869743 - samples/sec: 250.91 - lr: 0.050000\n",
            "2020-10-27 17:27:37,151 epoch 30 - iter 150/254 - loss 1.06811746 - samples/sec: 238.65 - lr: 0.050000\n",
            "2020-10-27 17:27:40,338 epoch 30 - iter 175/254 - loss 1.08229925 - samples/sec: 251.24 - lr: 0.050000\n",
            "2020-10-27 17:27:43,834 epoch 30 - iter 200/254 - loss 1.08558623 - samples/sec: 229.02 - lr: 0.050000\n",
            "2020-10-27 17:27:47,010 epoch 30 - iter 225/254 - loss 1.06668100 - samples/sec: 252.13 - lr: 0.050000\n",
            "2020-10-27 17:27:50,062 epoch 30 - iter 250/254 - loss 1.08061001 - samples/sec: 262.39 - lr: 0.050000\n",
            "2020-10-27 17:27:50,528 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:27:50,529 EPOCH 30 done: loss 1.0875 - lr 0.0500000\n",
            "2020-10-27 17:27:52,348 DEV : loss 2.0409984588623047 - score 0.9114\n",
            "2020-10-27 17:27:52,397 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:27:55,355 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:27:59,036 epoch 31 - iter 25/254 - loss 1.04089333 - samples/sec: 241.09 - lr: 0.050000\n",
            "2020-10-27 17:28:02,302 epoch 31 - iter 50/254 - loss 1.04691220 - samples/sec: 245.24 - lr: 0.050000\n",
            "2020-10-27 17:28:05,470 epoch 31 - iter 75/254 - loss 1.02141390 - samples/sec: 252.78 - lr: 0.050000\n",
            "2020-10-27 17:28:08,969 epoch 31 - iter 100/254 - loss 1.04787415 - samples/sec: 228.81 - lr: 0.050000\n",
            "2020-10-27 17:28:12,101 epoch 31 - iter 125/254 - loss 1.04887769 - samples/sec: 255.67 - lr: 0.050000\n",
            "2020-10-27 17:28:15,356 epoch 31 - iter 150/254 - loss 1.04145148 - samples/sec: 246.02 - lr: 0.050000\n",
            "2020-10-27 17:28:18,544 epoch 31 - iter 175/254 - loss 1.06179388 - samples/sec: 251.15 - lr: 0.050000\n",
            "2020-10-27 17:28:21,747 epoch 31 - iter 200/254 - loss 1.04909720 - samples/sec: 249.97 - lr: 0.050000\n",
            "2020-10-27 17:28:24,944 epoch 31 - iter 225/254 - loss 1.04265194 - samples/sec: 250.50 - lr: 0.050000\n",
            "2020-10-27 17:28:28,476 epoch 31 - iter 250/254 - loss 1.04905249 - samples/sec: 226.67 - lr: 0.050000\n",
            "2020-10-27 17:28:28,879 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:28:28,880 EPOCH 31 done: loss 1.0434 - lr 0.0500000\n",
            "2020-10-27 17:28:30,750 DEV : loss 1.9902448654174805 - score 0.9094\n",
            "2020-10-27 17:28:30,797 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:28:30,799 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:28:34,062 epoch 32 - iter 25/254 - loss 0.92994590 - samples/sec: 245.51 - lr: 0.050000\n",
            "2020-10-27 17:28:37,460 epoch 32 - iter 50/254 - loss 0.94821647 - samples/sec: 235.76 - lr: 0.050000\n",
            "2020-10-27 17:28:40,686 epoch 32 - iter 75/254 - loss 0.97897405 - samples/sec: 248.24 - lr: 0.050000\n",
            "2020-10-27 17:28:43,990 epoch 32 - iter 100/254 - loss 0.98877665 - samples/sec: 242.32 - lr: 0.050000\n",
            "2020-10-27 17:28:47,178 epoch 32 - iter 125/254 - loss 0.98814323 - samples/sec: 251.13 - lr: 0.050000\n",
            "2020-10-27 17:28:50,349 epoch 32 - iter 150/254 - loss 0.99393516 - samples/sec: 252.51 - lr: 0.050000\n",
            "2020-10-27 17:28:53,743 epoch 32 - iter 175/254 - loss 1.01107993 - samples/sec: 236.03 - lr: 0.050000\n",
            "2020-10-27 17:28:56,912 epoch 32 - iter 200/254 - loss 1.00271826 - samples/sec: 252.75 - lr: 0.050000\n",
            "2020-10-27 17:29:00,218 epoch 32 - iter 225/254 - loss 0.99876788 - samples/sec: 242.33 - lr: 0.050000\n",
            "2020-10-27 17:29:03,372 epoch 32 - iter 250/254 - loss 0.99689738 - samples/sec: 254.01 - lr: 0.050000\n",
            "2020-10-27 17:29:03,801 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:29:03,803 EPOCH 32 done: loss 1.0008 - lr 0.0500000\n",
            "2020-10-27 17:29:05,673 DEV : loss 1.9912399053573608 - score 0.9109\n",
            "2020-10-27 17:29:05,727 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:29:05,728 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:29:09,205 epoch 33 - iter 25/254 - loss 0.96246405 - samples/sec: 230.35 - lr: 0.050000\n",
            "2020-10-27 17:29:12,280 epoch 33 - iter 50/254 - loss 0.99861343 - samples/sec: 260.48 - lr: 0.050000\n",
            "2020-10-27 17:29:15,425 epoch 33 - iter 75/254 - loss 1.03983018 - samples/sec: 254.66 - lr: 0.050000\n",
            "2020-10-27 17:29:18,521 epoch 33 - iter 100/254 - loss 1.03316830 - samples/sec: 258.57 - lr: 0.050000\n",
            "2020-10-27 17:29:21,965 epoch 33 - iter 125/254 - loss 1.03113666 - samples/sec: 232.47 - lr: 0.050000\n",
            "2020-10-27 17:29:25,257 epoch 33 - iter 150/254 - loss 1.03483922 - samples/sec: 243.26 - lr: 0.050000\n",
            "2020-10-27 17:29:28,494 epoch 33 - iter 175/254 - loss 1.01645033 - samples/sec: 247.34 - lr: 0.050000\n",
            "2020-10-27 17:29:32,001 epoch 33 - iter 200/254 - loss 1.03150865 - samples/sec: 228.30 - lr: 0.050000\n",
            "2020-10-27 17:29:35,361 epoch 33 - iter 225/254 - loss 1.03361557 - samples/sec: 238.49 - lr: 0.050000\n",
            "2020-10-27 17:29:38,656 epoch 33 - iter 250/254 - loss 1.04457686 - samples/sec: 243.13 - lr: 0.050000\n",
            "2020-10-27 17:29:39,054 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:29:39,057 EPOCH 33 done: loss 1.0441 - lr 0.0500000\n",
            "2020-10-27 17:29:40,920 DEV : loss 1.946303367614746 - score 0.9124\n",
            "2020-10-27 17:29:40,972 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:29:43,954 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:29:47,651 epoch 34 - iter 25/254 - loss 0.98278091 - samples/sec: 238.73 - lr: 0.050000\n",
            "2020-10-27 17:29:50,913 epoch 34 - iter 50/254 - loss 0.96504094 - samples/sec: 245.45 - lr: 0.050000\n",
            "2020-10-27 17:29:54,016 epoch 34 - iter 75/254 - loss 0.94027052 - samples/sec: 258.23 - lr: 0.050000\n",
            "2020-10-27 17:29:57,485 epoch 34 - iter 100/254 - loss 0.92805572 - samples/sec: 230.82 - lr: 0.050000\n",
            "2020-10-27 17:30:00,544 epoch 34 - iter 125/254 - loss 0.91558485 - samples/sec: 261.91 - lr: 0.050000\n",
            "2020-10-27 17:30:03,967 epoch 34 - iter 150/254 - loss 0.91734100 - samples/sec: 233.87 - lr: 0.050000\n",
            "2020-10-27 17:30:07,203 epoch 34 - iter 175/254 - loss 0.93534333 - samples/sec: 247.49 - lr: 0.050000\n",
            "2020-10-27 17:30:10,434 epoch 34 - iter 200/254 - loss 0.94956187 - samples/sec: 247.87 - lr: 0.050000\n",
            "2020-10-27 17:30:13,572 epoch 34 - iter 225/254 - loss 0.95880289 - samples/sec: 255.14 - lr: 0.050000\n",
            "2020-10-27 17:30:16,667 epoch 34 - iter 250/254 - loss 0.96211573 - samples/sec: 258.93 - lr: 0.050000\n",
            "2020-10-27 17:30:17,314 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:30:17,315 EPOCH 34 done: loss 0.9642 - lr 0.0500000\n",
            "2020-10-27 17:30:19,622 DEV : loss 2.0211832523345947 - score 0.9112\n",
            "2020-10-27 17:30:19,670 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:30:19,671 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:30:22,859 epoch 35 - iter 25/254 - loss 0.95264185 - samples/sec: 251.26 - lr: 0.050000\n",
            "2020-10-27 17:30:26,202 epoch 35 - iter 50/254 - loss 0.92437223 - samples/sec: 239.65 - lr: 0.050000\n",
            "2020-10-27 17:30:29,519 epoch 35 - iter 75/254 - loss 0.96096667 - samples/sec: 241.43 - lr: 0.050000\n",
            "2020-10-27 17:30:32,703 epoch 35 - iter 100/254 - loss 0.95547298 - samples/sec: 251.47 - lr: 0.050000\n",
            "2020-10-27 17:30:35,931 epoch 35 - iter 125/254 - loss 0.98598980 - samples/sec: 248.15 - lr: 0.050000\n",
            "2020-10-27 17:30:39,114 epoch 35 - iter 150/254 - loss 0.99067151 - samples/sec: 251.61 - lr: 0.050000\n",
            "2020-10-27 17:30:42,358 epoch 35 - iter 175/254 - loss 0.97348726 - samples/sec: 246.81 - lr: 0.050000\n",
            "2020-10-27 17:30:45,829 epoch 35 - iter 200/254 - loss 0.97272737 - samples/sec: 230.77 - lr: 0.050000\n",
            "2020-10-27 17:30:49,050 epoch 35 - iter 225/254 - loss 0.97182919 - samples/sec: 248.64 - lr: 0.050000\n",
            "2020-10-27 17:30:52,262 epoch 35 - iter 250/254 - loss 0.97636406 - samples/sec: 249.46 - lr: 0.050000\n",
            "2020-10-27 17:30:52,738 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:30:52,739 EPOCH 35 done: loss 0.9741 - lr 0.0500000\n",
            "2020-10-27 17:30:54,585 DEV : loss 2.036879062652588 - score 0.9099\n",
            "2020-10-27 17:30:54,644 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:30:54,645 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:30:57,773 epoch 36 - iter 25/254 - loss 0.96187411 - samples/sec: 256.39 - lr: 0.050000\n",
            "2020-10-27 17:31:01,158 epoch 36 - iter 50/254 - loss 0.98043724 - samples/sec: 236.50 - lr: 0.050000\n",
            "2020-10-27 17:31:04,630 epoch 36 - iter 75/254 - loss 0.96356315 - samples/sec: 230.58 - lr: 0.050000\n",
            "2020-10-27 17:31:08,080 epoch 36 - iter 100/254 - loss 0.96761027 - samples/sec: 232.13 - lr: 0.050000\n",
            "2020-10-27 17:31:11,190 epoch 36 - iter 125/254 - loss 0.94431660 - samples/sec: 257.41 - lr: 0.050000\n",
            "2020-10-27 17:31:14,460 epoch 36 - iter 150/254 - loss 0.93275826 - samples/sec: 244.85 - lr: 0.050000\n",
            "2020-10-27 17:31:17,628 epoch 36 - iter 175/254 - loss 0.94652079 - samples/sec: 252.87 - lr: 0.050000\n",
            "2020-10-27 17:31:20,863 epoch 36 - iter 200/254 - loss 0.95584067 - samples/sec: 247.51 - lr: 0.050000\n",
            "2020-10-27 17:31:24,194 epoch 36 - iter 225/254 - loss 0.95591770 - samples/sec: 240.36 - lr: 0.050000\n",
            "2020-10-27 17:31:27,419 epoch 36 - iter 250/254 - loss 0.95267427 - samples/sec: 248.26 - lr: 0.050000\n",
            "2020-10-27 17:31:27,861 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:31:27,863 EPOCH 36 done: loss 0.9598 - lr 0.0500000\n",
            "2020-10-27 17:31:29,653 DEV : loss 2.022401809692383 - score 0.9084\n",
            "2020-10-27 17:31:29,706 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:31:29,707 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:31:33,115 epoch 37 - iter 25/254 - loss 0.96256863 - samples/sec: 235.05 - lr: 0.050000\n",
            "2020-10-27 17:31:36,284 epoch 37 - iter 50/254 - loss 0.88538766 - samples/sec: 252.80 - lr: 0.050000\n",
            "2020-10-27 17:31:39,483 epoch 37 - iter 75/254 - loss 0.88792356 - samples/sec: 250.46 - lr: 0.050000\n",
            "2020-10-27 17:31:42,717 epoch 37 - iter 100/254 - loss 0.89565657 - samples/sec: 247.58 - lr: 0.050000\n",
            "2020-10-27 17:31:45,875 epoch 37 - iter 125/254 - loss 0.89099869 - samples/sec: 253.55 - lr: 0.050000\n",
            "2020-10-27 17:31:49,267 epoch 37 - iter 150/254 - loss 0.91406636 - samples/sec: 236.07 - lr: 0.050000\n",
            "2020-10-27 17:31:52,701 epoch 37 - iter 175/254 - loss 0.92224965 - samples/sec: 233.15 - lr: 0.050000\n",
            "2020-10-27 17:31:55,841 epoch 37 - iter 200/254 - loss 0.91592581 - samples/sec: 255.18 - lr: 0.050000\n",
            "2020-10-27 17:31:59,001 epoch 37 - iter 225/254 - loss 0.92221878 - samples/sec: 253.32 - lr: 0.050000\n",
            "2020-10-27 17:32:02,143 epoch 37 - iter 250/254 - loss 0.91924123 - samples/sec: 254.91 - lr: 0.050000\n",
            "2020-10-27 17:32:02,583 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:32:02,585 EPOCH 37 done: loss 0.9159 - lr 0.0500000\n",
            "2020-10-27 17:32:04,457 DEV : loss 2.088564157485962 - score 0.909\n",
            "Epoch    37: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-10-27 17:32:04,504 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:32:04,505 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:32:07,787 epoch 38 - iter 25/254 - loss 0.85233483 - samples/sec: 244.06 - lr: 0.025000\n",
            "2020-10-27 17:32:10,922 epoch 38 - iter 50/254 - loss 0.80893814 - samples/sec: 255.41 - lr: 0.025000\n",
            "2020-10-27 17:32:14,461 epoch 38 - iter 75/254 - loss 0.85184903 - samples/sec: 226.27 - lr: 0.025000\n",
            "2020-10-27 17:32:17,701 epoch 38 - iter 100/254 - loss 0.82744481 - samples/sec: 247.22 - lr: 0.025000\n",
            "2020-10-27 17:32:21,008 epoch 38 - iter 125/254 - loss 0.82037140 - samples/sec: 242.12 - lr: 0.025000\n",
            "2020-10-27 17:32:24,525 epoch 38 - iter 150/254 - loss 0.84587091 - samples/sec: 227.66 - lr: 0.025000\n",
            "2020-10-27 17:32:27,792 epoch 38 - iter 175/254 - loss 0.85450235 - samples/sec: 245.20 - lr: 0.025000\n",
            "2020-10-27 17:32:30,986 epoch 38 - iter 200/254 - loss 0.85435658 - samples/sec: 250.71 - lr: 0.025000\n",
            "2020-10-27 17:32:34,147 epoch 38 - iter 225/254 - loss 0.85440643 - samples/sec: 253.25 - lr: 0.025000\n",
            "2020-10-27 17:32:37,423 epoch 38 - iter 250/254 - loss 0.85314821 - samples/sec: 244.48 - lr: 0.025000\n",
            "2020-10-27 17:32:37,875 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:32:37,878 EPOCH 38 done: loss 0.8520 - lr 0.0250000\n",
            "2020-10-27 17:32:39,754 DEV : loss 2.088327646255493 - score 0.9103\n",
            "2020-10-27 17:32:39,802 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:32:39,804 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:32:43,091 epoch 39 - iter 25/254 - loss 0.84510762 - samples/sec: 243.61 - lr: 0.025000\n",
            "2020-10-27 17:32:46,195 epoch 39 - iter 50/254 - loss 0.83893561 - samples/sec: 257.97 - lr: 0.025000\n",
            "2020-10-27 17:32:49,538 epoch 39 - iter 75/254 - loss 0.84047457 - samples/sec: 239.62 - lr: 0.025000\n",
            "2020-10-27 17:32:52,825 epoch 39 - iter 100/254 - loss 0.81204286 - samples/sec: 243.55 - lr: 0.025000\n",
            "2020-10-27 17:32:55,898 epoch 39 - iter 125/254 - loss 0.80800123 - samples/sec: 260.59 - lr: 0.025000\n",
            "2020-10-27 17:32:59,317 epoch 39 - iter 150/254 - loss 0.81259394 - samples/sec: 234.17 - lr: 0.025000\n",
            "2020-10-27 17:33:02,511 epoch 39 - iter 175/254 - loss 0.80488629 - samples/sec: 250.74 - lr: 0.025000\n",
            "2020-10-27 17:33:05,822 epoch 39 - iter 200/254 - loss 0.81686399 - samples/sec: 241.83 - lr: 0.025000\n",
            "2020-10-27 17:33:09,019 epoch 39 - iter 225/254 - loss 0.81054693 - samples/sec: 250.44 - lr: 0.025000\n",
            "2020-10-27 17:33:12,264 epoch 39 - iter 250/254 - loss 0.81106142 - samples/sec: 246.73 - lr: 0.025000\n",
            "2020-10-27 17:33:12,725 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:33:12,728 EPOCH 39 done: loss 0.8118 - lr 0.0250000\n",
            "2020-10-27 17:33:14,557 DEV : loss 2.060406446456909 - score 0.9095\n",
            "2020-10-27 17:33:14,611 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:33:14,612 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:33:17,794 epoch 40 - iter 25/254 - loss 0.80798468 - samples/sec: 251.86 - lr: 0.025000\n",
            "2020-10-27 17:33:21,054 epoch 40 - iter 50/254 - loss 0.79463693 - samples/sec: 245.66 - lr: 0.025000\n",
            "2020-10-27 17:33:24,332 epoch 40 - iter 75/254 - loss 0.82323921 - samples/sec: 244.25 - lr: 0.025000\n",
            "2020-10-27 17:33:27,840 epoch 40 - iter 100/254 - loss 0.81749630 - samples/sec: 228.37 - lr: 0.025000\n",
            "2020-10-27 17:33:31,041 epoch 40 - iter 125/254 - loss 0.80849891 - samples/sec: 250.19 - lr: 0.025000\n",
            "2020-10-27 17:33:34,400 epoch 40 - iter 150/254 - loss 0.79875394 - samples/sec: 238.32 - lr: 0.025000\n",
            "2020-10-27 17:33:37,642 epoch 40 - iter 175/254 - loss 0.80452769 - samples/sec: 247.11 - lr: 0.025000\n",
            "2020-10-27 17:33:40,881 epoch 40 - iter 200/254 - loss 0.81176146 - samples/sec: 247.20 - lr: 0.025000\n",
            "2020-10-27 17:33:43,953 epoch 40 - iter 225/254 - loss 0.80314363 - samples/sec: 260.68 - lr: 0.025000\n",
            "2020-10-27 17:33:47,117 epoch 40 - iter 250/254 - loss 0.80285980 - samples/sec: 253.13 - lr: 0.025000\n",
            "2020-10-27 17:33:47,527 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:33:47,528 EPOCH 40 done: loss 0.8000 - lr 0.0250000\n",
            "2020-10-27 17:33:49,431 DEV : loss 2.083144426345825 - score 0.9109\n",
            "2020-10-27 17:33:49,483 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:33:49,486 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:33:52,848 epoch 41 - iter 25/254 - loss 0.76562116 - samples/sec: 238.20 - lr: 0.025000\n",
            "2020-10-27 17:33:55,941 epoch 41 - iter 50/254 - loss 0.77793226 - samples/sec: 258.85 - lr: 0.025000\n",
            "2020-10-27 17:33:59,045 epoch 41 - iter 75/254 - loss 0.76904819 - samples/sec: 258.00 - lr: 0.025000\n",
            "2020-10-27 17:34:02,486 epoch 41 - iter 100/254 - loss 0.77242928 - samples/sec: 232.65 - lr: 0.025000\n",
            "2020-10-27 17:34:05,652 epoch 41 - iter 125/254 - loss 0.78999297 - samples/sec: 253.06 - lr: 0.025000\n",
            "2020-10-27 17:34:09,018 epoch 41 - iter 150/254 - loss 0.79372296 - samples/sec: 237.91 - lr: 0.025000\n",
            "2020-10-27 17:34:12,230 epoch 41 - iter 175/254 - loss 0.80485891 - samples/sec: 249.29 - lr: 0.025000\n",
            "2020-10-27 17:34:15,363 epoch 41 - iter 200/254 - loss 0.80599748 - samples/sec: 255.56 - lr: 0.025000\n",
            "2020-10-27 17:34:18,727 epoch 41 - iter 225/254 - loss 0.80406371 - samples/sec: 238.04 - lr: 0.025000\n",
            "2020-10-27 17:34:22,050 epoch 41 - iter 250/254 - loss 0.80295692 - samples/sec: 241.15 - lr: 0.025000\n",
            "2020-10-27 17:34:22,521 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:34:22,522 EPOCH 41 done: loss 0.8026 - lr 0.0250000\n",
            "2020-10-27 17:34:24,411 DEV : loss 2.0058534145355225 - score 0.9152\n",
            "2020-10-27 17:34:24,465 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:34:27,363 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:34:30,656 epoch 42 - iter 25/254 - loss 0.73919063 - samples/sec: 243.35 - lr: 0.025000\n",
            "2020-10-27 17:34:33,921 epoch 42 - iter 50/254 - loss 0.77962962 - samples/sec: 245.28 - lr: 0.025000\n",
            "2020-10-27 17:34:37,169 epoch 42 - iter 75/254 - loss 0.79038336 - samples/sec: 246.48 - lr: 0.025000\n",
            "2020-10-27 17:34:40,615 epoch 42 - iter 100/254 - loss 0.79848851 - samples/sec: 232.36 - lr: 0.025000\n",
            "2020-10-27 17:34:44,123 epoch 42 - iter 125/254 - loss 0.80120410 - samples/sec: 228.24 - lr: 0.025000\n",
            "2020-10-27 17:34:47,286 epoch 42 - iter 150/254 - loss 0.78678741 - samples/sec: 253.13 - lr: 0.025000\n",
            "2020-10-27 17:34:50,685 epoch 42 - iter 175/254 - loss 0.79150097 - samples/sec: 235.60 - lr: 0.025000\n",
            "2020-10-27 17:34:53,968 epoch 42 - iter 200/254 - loss 0.78666127 - samples/sec: 244.03 - lr: 0.025000\n",
            "2020-10-27 17:34:57,399 epoch 42 - iter 225/254 - loss 0.78375883 - samples/sec: 233.35 - lr: 0.025000\n",
            "2020-10-27 17:35:00,683 epoch 42 - iter 250/254 - loss 0.77979552 - samples/sec: 243.83 - lr: 0.025000\n",
            "2020-10-27 17:35:01,128 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:35:01,129 EPOCH 42 done: loss 0.7742 - lr 0.0250000\n",
            "2020-10-27 17:35:03,464 DEV : loss 2.0916855335235596 - score 0.9135\n",
            "2020-10-27 17:35:03,512 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:35:03,513 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:35:07,210 epoch 43 - iter 25/254 - loss 0.72931220 - samples/sec: 216.76 - lr: 0.025000\n",
            "2020-10-27 17:35:10,497 epoch 43 - iter 50/254 - loss 0.70737331 - samples/sec: 243.64 - lr: 0.025000\n",
            "2020-10-27 17:35:13,836 epoch 43 - iter 75/254 - loss 0.75707527 - samples/sec: 239.80 - lr: 0.025000\n",
            "2020-10-27 17:35:16,907 epoch 43 - iter 100/254 - loss 0.76219266 - samples/sec: 260.67 - lr: 0.025000\n",
            "2020-10-27 17:35:20,035 epoch 43 - iter 125/254 - loss 0.74826783 - samples/sec: 255.98 - lr: 0.025000\n",
            "2020-10-27 17:35:23,360 epoch 43 - iter 150/254 - loss 0.76722869 - samples/sec: 240.90 - lr: 0.025000\n",
            "2020-10-27 17:35:26,553 epoch 43 - iter 175/254 - loss 0.76614611 - samples/sec: 250.98 - lr: 0.025000\n",
            "2020-10-27 17:35:29,833 epoch 43 - iter 200/254 - loss 0.76209240 - samples/sec: 244.07 - lr: 0.025000\n",
            "2020-10-27 17:35:33,139 epoch 43 - iter 225/254 - loss 0.75196574 - samples/sec: 242.35 - lr: 0.025000\n",
            "2020-10-27 17:35:36,283 epoch 43 - iter 250/254 - loss 0.75542205 - samples/sec: 254.70 - lr: 0.025000\n",
            "2020-10-27 17:35:36,722 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:35:36,723 EPOCH 43 done: loss 0.7530 - lr 0.0250000\n",
            "2020-10-27 17:35:38,583 DEV : loss 2.104879140853882 - score 0.9119\n",
            "2020-10-27 17:35:38,633 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:35:38,637 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:35:42,023 epoch 44 - iter 25/254 - loss 0.73843185 - samples/sec: 236.52 - lr: 0.025000\n",
            "2020-10-27 17:35:45,234 epoch 44 - iter 50/254 - loss 0.73896645 - samples/sec: 249.38 - lr: 0.025000\n",
            "2020-10-27 17:35:48,444 epoch 44 - iter 75/254 - loss 0.75583740 - samples/sec: 249.47 - lr: 0.025000\n",
            "2020-10-27 17:35:51,729 epoch 44 - iter 100/254 - loss 0.75038040 - samples/sec: 243.72 - lr: 0.025000\n",
            "2020-10-27 17:35:55,289 epoch 44 - iter 125/254 - loss 0.76770843 - samples/sec: 224.95 - lr: 0.025000\n",
            "2020-10-27 17:35:58,636 epoch 44 - iter 150/254 - loss 0.76854153 - samples/sec: 239.17 - lr: 0.025000\n",
            "2020-10-27 17:36:01,869 epoch 44 - iter 175/254 - loss 0.75241037 - samples/sec: 247.81 - lr: 0.025000\n",
            "2020-10-27 17:36:05,105 epoch 44 - iter 200/254 - loss 0.75498139 - samples/sec: 247.46 - lr: 0.025000\n",
            "2020-10-27 17:36:08,228 epoch 44 - iter 225/254 - loss 0.75223692 - samples/sec: 256.40 - lr: 0.025000\n",
            "2020-10-27 17:36:11,425 epoch 44 - iter 250/254 - loss 0.74861588 - samples/sec: 250.52 - lr: 0.025000\n",
            "2020-10-27 17:36:11,858 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:36:11,860 EPOCH 44 done: loss 0.7515 - lr 0.0250000\n",
            "2020-10-27 17:36:13,718 DEV : loss 2.0932247638702393 - score 0.9121\n",
            "2020-10-27 17:36:13,768 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:36:13,769 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:36:17,114 epoch 45 - iter 25/254 - loss 0.77635155 - samples/sec: 239.40 - lr: 0.025000\n",
            "2020-10-27 17:36:20,572 epoch 45 - iter 50/254 - loss 0.76977548 - samples/sec: 231.62 - lr: 0.025000\n",
            "2020-10-27 17:36:23,857 epoch 45 - iter 75/254 - loss 0.74587710 - samples/sec: 243.78 - lr: 0.025000\n",
            "2020-10-27 17:36:27,201 epoch 45 - iter 100/254 - loss 0.76186210 - samples/sec: 239.44 - lr: 0.025000\n",
            "2020-10-27 17:36:30,416 epoch 45 - iter 125/254 - loss 0.74667697 - samples/sec: 249.05 - lr: 0.025000\n",
            "2020-10-27 17:36:33,438 epoch 45 - iter 150/254 - loss 0.74276243 - samples/sec: 264.92 - lr: 0.025000\n",
            "2020-10-27 17:36:36,686 epoch 45 - iter 175/254 - loss 0.73663088 - samples/sec: 246.52 - lr: 0.025000\n",
            "2020-10-27 17:36:39,968 epoch 45 - iter 200/254 - loss 0.73072443 - samples/sec: 244.01 - lr: 0.025000\n",
            "2020-10-27 17:36:43,049 epoch 45 - iter 225/254 - loss 0.73858866 - samples/sec: 259.87 - lr: 0.025000\n",
            "2020-10-27 17:36:46,390 epoch 45 - iter 250/254 - loss 0.73378948 - samples/sec: 239.67 - lr: 0.025000\n",
            "2020-10-27 17:36:46,843 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:36:46,844 EPOCH 45 done: loss 0.7351 - lr 0.0250000\n",
            "2020-10-27 17:36:48,709 DEV : loss 2.144139289855957 - score 0.9111\n",
            "Epoch    45: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-10-27 17:36:48,762 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:36:48,765 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:36:51,979 epoch 46 - iter 25/254 - loss 0.63716264 - samples/sec: 249.35 - lr: 0.012500\n",
            "2020-10-27 17:36:55,296 epoch 46 - iter 50/254 - loss 0.69310103 - samples/sec: 241.47 - lr: 0.012500\n",
            "2020-10-27 17:36:58,626 epoch 46 - iter 75/254 - loss 0.72169947 - samples/sec: 240.42 - lr: 0.012500\n",
            "2020-10-27 17:37:01,675 epoch 46 - iter 100/254 - loss 0.70552043 - samples/sec: 262.68 - lr: 0.012500\n",
            "2020-10-27 17:37:04,798 epoch 46 - iter 125/254 - loss 0.69854072 - samples/sec: 256.40 - lr: 0.012500\n",
            "2020-10-27 17:37:08,272 epoch 46 - iter 150/254 - loss 0.70129267 - samples/sec: 230.45 - lr: 0.012500\n",
            "2020-10-27 17:37:11,502 epoch 46 - iter 175/254 - loss 0.71168184 - samples/sec: 247.87 - lr: 0.012500\n",
            "2020-10-27 17:37:14,795 epoch 46 - iter 200/254 - loss 0.71410124 - samples/sec: 243.18 - lr: 0.012500\n",
            "2020-10-27 17:37:18,103 epoch 46 - iter 225/254 - loss 0.71284196 - samples/sec: 242.07 - lr: 0.012500\n",
            "2020-10-27 17:37:21,403 epoch 46 - iter 250/254 - loss 0.69858749 - samples/sec: 242.77 - lr: 0.012500\n",
            "2020-10-27 17:37:21,805 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:37:21,806 EPOCH 46 done: loss 0.6953 - lr 0.0125000\n",
            "2020-10-27 17:37:23,635 DEV : loss 2.112075090408325 - score 0.9123\n",
            "2020-10-27 17:37:23,686 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:37:23,687 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:37:26,969 epoch 47 - iter 25/254 - loss 0.71474343 - samples/sec: 244.05 - lr: 0.012500\n",
            "2020-10-27 17:37:30,494 epoch 47 - iter 50/254 - loss 0.69101003 - samples/sec: 227.22 - lr: 0.012500\n",
            "2020-10-27 17:37:33,575 epoch 47 - iter 75/254 - loss 0.68672411 - samples/sec: 259.91 - lr: 0.012500\n",
            "2020-10-27 17:37:36,796 epoch 47 - iter 100/254 - loss 0.69297145 - samples/sec: 248.57 - lr: 0.012500\n",
            "2020-10-27 17:37:40,076 epoch 47 - iter 125/254 - loss 0.69559232 - samples/sec: 244.13 - lr: 0.012500\n",
            "2020-10-27 17:37:43,357 epoch 47 - iter 150/254 - loss 0.69630637 - samples/sec: 244.03 - lr: 0.012500\n",
            "2020-10-27 17:37:46,797 epoch 47 - iter 175/254 - loss 0.68985799 - samples/sec: 232.73 - lr: 0.012500\n",
            "2020-10-27 17:37:50,077 epoch 47 - iter 200/254 - loss 0.68663967 - samples/sec: 244.27 - lr: 0.012500\n",
            "2020-10-27 17:37:53,489 epoch 47 - iter 225/254 - loss 0.69237754 - samples/sec: 234.71 - lr: 0.012500\n",
            "2020-10-27 17:37:56,819 epoch 47 - iter 250/254 - loss 0.68904041 - samples/sec: 240.56 - lr: 0.012500\n",
            "2020-10-27 17:37:57,227 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:37:57,228 EPOCH 47 done: loss 0.6881 - lr 0.0125000\n",
            "2020-10-27 17:37:59,086 DEV : loss 2.114677667617798 - score 0.9129\n",
            "2020-10-27 17:37:59,137 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:37:59,138 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:38:02,398 epoch 48 - iter 25/254 - loss 0.65766986 - samples/sec: 245.89 - lr: 0.012500\n",
            "2020-10-27 17:38:05,653 epoch 48 - iter 50/254 - loss 0.70006983 - samples/sec: 245.99 - lr: 0.012500\n",
            "2020-10-27 17:38:09,122 epoch 48 - iter 75/254 - loss 0.70657333 - samples/sec: 230.81 - lr: 0.012500\n",
            "2020-10-27 17:38:12,313 epoch 48 - iter 100/254 - loss 0.70233549 - samples/sec: 250.96 - lr: 0.012500\n",
            "2020-10-27 17:38:15,513 epoch 48 - iter 125/254 - loss 0.69478477 - samples/sec: 250.38 - lr: 0.012500\n",
            "2020-10-27 17:38:18,677 epoch 48 - iter 150/254 - loss 0.68624074 - samples/sec: 253.25 - lr: 0.012500\n",
            "2020-10-27 17:38:21,923 epoch 48 - iter 175/254 - loss 0.68244743 - samples/sec: 246.69 - lr: 0.012500\n",
            "2020-10-27 17:38:25,205 epoch 48 - iter 200/254 - loss 0.68549006 - samples/sec: 244.10 - lr: 0.012500\n",
            "2020-10-27 17:38:28,540 epoch 48 - iter 225/254 - loss 0.68451016 - samples/sec: 240.10 - lr: 0.012500\n",
            "2020-10-27 17:38:32,038 epoch 48 - iter 250/254 - loss 0.68699177 - samples/sec: 228.86 - lr: 0.012500\n",
            "2020-10-27 17:38:32,488 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:38:32,490 EPOCH 48 done: loss 0.6860 - lr 0.0125000\n",
            "2020-10-27 17:38:34,381 DEV : loss 2.133408546447754 - score 0.9112\n",
            "2020-10-27 17:38:34,430 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:38:34,431 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:38:37,657 epoch 49 - iter 25/254 - loss 0.65223467 - samples/sec: 248.27 - lr: 0.012500\n",
            "2020-10-27 17:38:40,769 epoch 49 - iter 50/254 - loss 0.65582706 - samples/sec: 257.32 - lr: 0.012500\n",
            "2020-10-27 17:38:44,206 epoch 49 - iter 75/254 - loss 0.65229825 - samples/sec: 232.97 - lr: 0.012500\n",
            "2020-10-27 17:38:47,433 epoch 49 - iter 100/254 - loss 0.65034116 - samples/sec: 248.07 - lr: 0.012500\n",
            "2020-10-27 17:38:50,608 epoch 49 - iter 125/254 - loss 0.64433582 - samples/sec: 252.24 - lr: 0.012500\n",
            "2020-10-27 17:38:53,914 epoch 49 - iter 150/254 - loss 0.65807422 - samples/sec: 242.18 - lr: 0.012500\n",
            "2020-10-27 17:38:57,444 epoch 49 - iter 175/254 - loss 0.67151243 - samples/sec: 226.77 - lr: 0.012500\n",
            "2020-10-27 17:39:00,782 epoch 49 - iter 200/254 - loss 0.67373087 - samples/sec: 240.15 - lr: 0.012500\n",
            "2020-10-27 17:39:03,924 epoch 49 - iter 225/254 - loss 0.66252996 - samples/sec: 254.85 - lr: 0.012500\n",
            "2020-10-27 17:39:07,248 epoch 49 - iter 250/254 - loss 0.66408374 - samples/sec: 240.92 - lr: 0.012500\n",
            "2020-10-27 17:39:07,699 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:39:07,700 EPOCH 49 done: loss 0.6649 - lr 0.0125000\n",
            "2020-10-27 17:39:09,574 DEV : loss 2.138373374938965 - score 0.9123\n",
            "Epoch    49: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-10-27 17:39:09,632 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:39:09,634 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:39:12,919 epoch 50 - iter 25/254 - loss 0.60206049 - samples/sec: 243.76 - lr: 0.006250\n",
            "2020-10-27 17:39:16,125 epoch 50 - iter 50/254 - loss 0.60769093 - samples/sec: 249.81 - lr: 0.006250\n",
            "2020-10-27 17:39:19,491 epoch 50 - iter 75/254 - loss 0.61667941 - samples/sec: 237.82 - lr: 0.006250\n",
            "2020-10-27 17:39:22,811 epoch 50 - iter 100/254 - loss 0.63454641 - samples/sec: 241.22 - lr: 0.006250\n",
            "2020-10-27 17:39:26,180 epoch 50 - iter 125/254 - loss 0.64169506 - samples/sec: 237.63 - lr: 0.006250\n",
            "2020-10-27 17:39:29,443 epoch 50 - iter 150/254 - loss 0.64089483 - samples/sec: 245.44 - lr: 0.006250\n",
            "2020-10-27 17:39:32,744 epoch 50 - iter 175/254 - loss 0.64335289 - samples/sec: 242.55 - lr: 0.006250\n",
            "2020-10-27 17:39:35,887 epoch 50 - iter 200/254 - loss 0.65723239 - samples/sec: 254.88 - lr: 0.006250\n",
            "2020-10-27 17:39:39,097 epoch 50 - iter 225/254 - loss 0.66432976 - samples/sec: 249.43 - lr: 0.006250\n",
            "2020-10-27 17:39:42,448 epoch 50 - iter 250/254 - loss 0.66208651 - samples/sec: 238.92 - lr: 0.006250\n",
            "2020-10-27 17:39:42,901 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:39:42,902 EPOCH 50 done: loss 0.6572 - lr 0.0062500\n",
            "2020-10-27 17:39:44,779 DEV : loss 2.1326441764831543 - score 0.9122\n",
            "2020-10-27 17:39:44,828 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:39:44,830 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:39:47,957 epoch 51 - iter 25/254 - loss 0.61019094 - samples/sec: 256.09 - lr: 0.006250\n",
            "2020-10-27 17:39:51,322 epoch 51 - iter 50/254 - loss 0.62136985 - samples/sec: 238.11 - lr: 0.006250\n",
            "2020-10-27 17:39:54,627 epoch 51 - iter 75/254 - loss 0.65271473 - samples/sec: 242.26 - lr: 0.006250\n",
            "2020-10-27 17:39:58,035 epoch 51 - iter 100/254 - loss 0.63943109 - samples/sec: 234.96 - lr: 0.006250\n",
            "2020-10-27 17:40:01,496 epoch 51 - iter 125/254 - loss 0.65346303 - samples/sec: 231.45 - lr: 0.006250\n",
            "2020-10-27 17:40:04,706 epoch 51 - iter 150/254 - loss 0.65878664 - samples/sec: 249.42 - lr: 0.006250\n",
            "2020-10-27 17:40:07,931 epoch 51 - iter 175/254 - loss 0.65821637 - samples/sec: 248.39 - lr: 0.006250\n",
            "2020-10-27 17:40:11,551 epoch 51 - iter 200/254 - loss 0.65796931 - samples/sec: 221.26 - lr: 0.006250\n",
            "2020-10-27 17:40:14,849 epoch 51 - iter 225/254 - loss 0.65997976 - samples/sec: 242.78 - lr: 0.006250\n",
            "2020-10-27 17:40:18,150 epoch 51 - iter 250/254 - loss 0.65601928 - samples/sec: 242.61 - lr: 0.006250\n",
            "2020-10-27 17:40:18,608 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:40:18,609 EPOCH 51 done: loss 0.6566 - lr 0.0062500\n",
            "2020-10-27 17:40:20,452 DEV : loss 2.121055841445923 - score 0.9137\n",
            "2020-10-27 17:40:20,500 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:40:20,501 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:40:23,731 epoch 52 - iter 25/254 - loss 0.62467220 - samples/sec: 247.93 - lr: 0.006250\n",
            "2020-10-27 17:40:27,107 epoch 52 - iter 50/254 - loss 0.67651706 - samples/sec: 237.21 - lr: 0.006250\n",
            "2020-10-27 17:40:30,507 epoch 52 - iter 75/254 - loss 0.67810693 - samples/sec: 235.44 - lr: 0.006250\n",
            "2020-10-27 17:40:33,910 epoch 52 - iter 100/254 - loss 0.66891631 - samples/sec: 235.28 - lr: 0.006250\n",
            "2020-10-27 17:40:37,335 epoch 52 - iter 125/254 - loss 0.67792275 - samples/sec: 233.80 - lr: 0.006250\n",
            "2020-10-27 17:40:40,567 epoch 52 - iter 150/254 - loss 0.68437879 - samples/sec: 247.74 - lr: 0.006250\n",
            "2020-10-27 17:40:43,693 epoch 52 - iter 175/254 - loss 0.67563310 - samples/sec: 256.18 - lr: 0.006250\n",
            "2020-10-27 17:40:46,680 epoch 52 - iter 200/254 - loss 0.67127618 - samples/sec: 268.10 - lr: 0.006250\n",
            "2020-10-27 17:40:49,932 epoch 52 - iter 225/254 - loss 0.66882056 - samples/sec: 246.20 - lr: 0.006250\n",
            "2020-10-27 17:40:53,388 epoch 52 - iter 250/254 - loss 0.66515889 - samples/sec: 231.66 - lr: 0.006250\n",
            "2020-10-27 17:40:53,852 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:40:53,855 EPOCH 52 done: loss 0.6643 - lr 0.0062500\n",
            "2020-10-27 17:40:55,681 DEV : loss 2.1321651935577393 - score 0.913\n",
            "2020-10-27 17:40:55,729 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:40:55,730 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:40:59,007 epoch 53 - iter 25/254 - loss 0.50414023 - samples/sec: 244.45 - lr: 0.006250\n",
            "2020-10-27 17:41:02,510 epoch 53 - iter 50/254 - loss 0.54537217 - samples/sec: 228.56 - lr: 0.006250\n",
            "2020-10-27 17:41:06,074 epoch 53 - iter 75/254 - loss 0.59727443 - samples/sec: 224.67 - lr: 0.006250\n",
            "2020-10-27 17:41:09,281 epoch 53 - iter 100/254 - loss 0.58443404 - samples/sec: 249.65 - lr: 0.006250\n",
            "2020-10-27 17:41:12,609 epoch 53 - iter 125/254 - loss 0.59024561 - samples/sec: 240.62 - lr: 0.006250\n",
            "2020-10-27 17:41:16,009 epoch 53 - iter 150/254 - loss 0.60912076 - samples/sec: 235.51 - lr: 0.006250\n",
            "2020-10-27 17:41:19,550 epoch 53 - iter 175/254 - loss 0.62215610 - samples/sec: 226.21 - lr: 0.006250\n",
            "2020-10-27 17:41:22,671 epoch 53 - iter 200/254 - loss 0.62194322 - samples/sec: 256.58 - lr: 0.006250\n",
            "2020-10-27 17:41:26,089 epoch 53 - iter 225/254 - loss 0.62576814 - samples/sec: 234.40 - lr: 0.006250\n",
            "2020-10-27 17:41:29,222 epoch 53 - iter 250/254 - loss 0.62444123 - samples/sec: 255.53 - lr: 0.006250\n",
            "2020-10-27 17:41:29,760 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:41:29,762 EPOCH 53 done: loss 0.6244 - lr 0.0062500\n",
            "2020-10-27 17:41:31,698 DEV : loss 2.1426899433135986 - score 0.9127\n",
            "Epoch    53: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-10-27 17:41:31,748 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:41:31,749 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:41:35,245 epoch 54 - iter 25/254 - loss 0.67638164 - samples/sec: 229.08 - lr: 0.003125\n",
            "2020-10-27 17:41:38,825 epoch 54 - iter 50/254 - loss 0.65493836 - samples/sec: 223.72 - lr: 0.003125\n",
            "2020-10-27 17:41:42,177 epoch 54 - iter 75/254 - loss 0.66893745 - samples/sec: 238.98 - lr: 0.003125\n",
            "2020-10-27 17:41:45,520 epoch 54 - iter 100/254 - loss 0.64949461 - samples/sec: 239.57 - lr: 0.003125\n",
            "2020-10-27 17:41:49,003 epoch 54 - iter 125/254 - loss 0.64679277 - samples/sec: 229.87 - lr: 0.003125\n",
            "2020-10-27 17:41:52,367 epoch 54 - iter 150/254 - loss 0.65195355 - samples/sec: 238.03 - lr: 0.003125\n",
            "2020-10-27 17:41:55,616 epoch 54 - iter 175/254 - loss 0.64381557 - samples/sec: 246.51 - lr: 0.003125\n",
            "2020-10-27 17:41:59,108 epoch 54 - iter 200/254 - loss 0.64460543 - samples/sec: 229.30 - lr: 0.003125\n",
            "2020-10-27 17:42:02,437 epoch 54 - iter 225/254 - loss 0.64543187 - samples/sec: 240.55 - lr: 0.003125\n",
            "2020-10-27 17:42:05,623 epoch 54 - iter 250/254 - loss 0.64072002 - samples/sec: 251.38 - lr: 0.003125\n",
            "2020-10-27 17:42:06,134 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:42:06,134 EPOCH 54 done: loss 0.6393 - lr 0.0031250\n",
            "2020-10-27 17:42:07,969 DEV : loss 2.1328184604644775 - score 0.913\n",
            "2020-10-27 17:42:08,015 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:42:08,016 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:42:11,467 epoch 55 - iter 25/254 - loss 0.64710530 - samples/sec: 232.15 - lr: 0.003125\n",
            "2020-10-27 17:42:14,976 epoch 55 - iter 50/254 - loss 0.65727648 - samples/sec: 228.21 - lr: 0.003125\n",
            "2020-10-27 17:42:18,295 epoch 55 - iter 75/254 - loss 0.64619635 - samples/sec: 241.23 - lr: 0.003125\n",
            "2020-10-27 17:42:21,345 epoch 55 - iter 100/254 - loss 0.64580538 - samples/sec: 262.67 - lr: 0.003125\n",
            "2020-10-27 17:42:24,544 epoch 55 - iter 125/254 - loss 0.63427282 - samples/sec: 250.45 - lr: 0.003125\n",
            "2020-10-27 17:42:27,836 epoch 55 - iter 150/254 - loss 0.62317457 - samples/sec: 243.35 - lr: 0.003125\n",
            "2020-10-27 17:42:31,125 epoch 55 - iter 175/254 - loss 0.62265889 - samples/sec: 243.50 - lr: 0.003125\n",
            "2020-10-27 17:42:34,347 epoch 55 - iter 200/254 - loss 0.61947232 - samples/sec: 248.55 - lr: 0.003125\n",
            "2020-10-27 17:42:37,734 epoch 55 - iter 225/254 - loss 0.62120210 - samples/sec: 236.52 - lr: 0.003125\n",
            "2020-10-27 17:42:41,058 epoch 55 - iter 250/254 - loss 0.63067501 - samples/sec: 241.07 - lr: 0.003125\n",
            "2020-10-27 17:42:41,478 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:42:41,481 EPOCH 55 done: loss 0.6336 - lr 0.0031250\n",
            "2020-10-27 17:42:43,336 DEV : loss 2.137350082397461 - score 0.9137\n",
            "2020-10-27 17:42:43,383 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:42:43,384 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:42:46,573 epoch 56 - iter 25/254 - loss 0.67592819 - samples/sec: 251.23 - lr: 0.003125\n",
            "2020-10-27 17:42:49,797 epoch 56 - iter 50/254 - loss 0.63572361 - samples/sec: 248.38 - lr: 0.003125\n",
            "2020-10-27 17:42:52,975 epoch 56 - iter 75/254 - loss 0.62579378 - samples/sec: 252.07 - lr: 0.003125\n",
            "2020-10-27 17:42:56,247 epoch 56 - iter 100/254 - loss 0.61192079 - samples/sec: 244.83 - lr: 0.003125\n",
            "2020-10-27 17:42:59,997 epoch 56 - iter 125/254 - loss 0.62266541 - samples/sec: 213.45 - lr: 0.003125\n",
            "2020-10-27 17:43:03,042 epoch 56 - iter 150/254 - loss 0.62424044 - samples/sec: 263.02 - lr: 0.003125\n",
            "2020-10-27 17:43:06,448 epoch 56 - iter 175/254 - loss 0.62562970 - samples/sec: 235.12 - lr: 0.003125\n",
            "2020-10-27 17:43:09,791 epoch 56 - iter 200/254 - loss 0.63977952 - samples/sec: 239.48 - lr: 0.003125\n",
            "2020-10-27 17:43:13,032 epoch 56 - iter 225/254 - loss 0.64211976 - samples/sec: 247.17 - lr: 0.003125\n",
            "2020-10-27 17:43:16,177 epoch 56 - iter 250/254 - loss 0.64012784 - samples/sec: 254.57 - lr: 0.003125\n",
            "2020-10-27 17:43:16,620 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:43:16,621 EPOCH 56 done: loss 0.6391 - lr 0.0031250\n",
            "2020-10-27 17:43:18,501 DEV : loss 2.134869337081909 - score 0.9134\n",
            "2020-10-27 17:43:18,553 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:43:18,554 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:43:21,923 epoch 57 - iter 25/254 - loss 0.55229640 - samples/sec: 237.71 - lr: 0.003125\n",
            "2020-10-27 17:43:25,085 epoch 57 - iter 50/254 - loss 0.57107553 - samples/sec: 253.28 - lr: 0.003125\n",
            "2020-10-27 17:43:28,235 epoch 57 - iter 75/254 - loss 0.57480824 - samples/sec: 254.32 - lr: 0.003125\n",
            "2020-10-27 17:43:31,669 epoch 57 - iter 100/254 - loss 0.59749846 - samples/sec: 233.11 - lr: 0.003125\n",
            "2020-10-27 17:43:34,694 epoch 57 - iter 125/254 - loss 0.59438745 - samples/sec: 264.72 - lr: 0.003125\n",
            "2020-10-27 17:43:38,022 epoch 57 - iter 150/254 - loss 0.61388250 - samples/sec: 240.66 - lr: 0.003125\n",
            "2020-10-27 17:43:41,538 epoch 57 - iter 175/254 - loss 0.61577150 - samples/sec: 227.68 - lr: 0.003125\n",
            "2020-10-27 17:43:44,880 epoch 57 - iter 200/254 - loss 0.62375057 - samples/sec: 239.61 - lr: 0.003125\n",
            "2020-10-27 17:43:48,035 epoch 57 - iter 225/254 - loss 0.62969181 - samples/sec: 253.90 - lr: 0.003125\n",
            "2020-10-27 17:43:51,302 epoch 57 - iter 250/254 - loss 0.62891365 - samples/sec: 245.09 - lr: 0.003125\n",
            "2020-10-27 17:43:51,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:43:51,735 EPOCH 57 done: loss 0.6331 - lr 0.0031250\n",
            "2020-10-27 17:43:53,590 DEV : loss 2.135572910308838 - score 0.9143\n",
            "Epoch    57: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2020-10-27 17:43:53,637 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:43:53,638 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:43:57,000 epoch 58 - iter 25/254 - loss 0.62053137 - samples/sec: 238.27 - lr: 0.001563\n",
            "2020-10-27 17:44:00,317 epoch 58 - iter 50/254 - loss 0.60998240 - samples/sec: 241.39 - lr: 0.001563\n",
            "2020-10-27 17:44:03,420 epoch 58 - iter 75/254 - loss 0.62455424 - samples/sec: 258.02 - lr: 0.001563\n",
            "2020-10-27 17:44:06,611 epoch 58 - iter 100/254 - loss 0.62570108 - samples/sec: 251.11 - lr: 0.001563\n",
            "2020-10-27 17:44:09,929 epoch 58 - iter 125/254 - loss 0.63433853 - samples/sec: 241.29 - lr: 0.001563\n",
            "2020-10-27 17:44:13,339 epoch 58 - iter 150/254 - loss 0.64940360 - samples/sec: 234.81 - lr: 0.001563\n",
            "2020-10-27 17:44:16,729 epoch 58 - iter 175/254 - loss 0.65097070 - samples/sec: 236.19 - lr: 0.001563\n",
            "2020-10-27 17:44:19,933 epoch 58 - iter 200/254 - loss 0.65296159 - samples/sec: 249.98 - lr: 0.001563\n",
            "2020-10-27 17:44:23,143 epoch 58 - iter 225/254 - loss 0.64510898 - samples/sec: 249.59 - lr: 0.001563\n",
            "2020-10-27 17:44:26,458 epoch 58 - iter 250/254 - loss 0.64692409 - samples/sec: 241.55 - lr: 0.001563\n",
            "2020-10-27 17:44:26,884 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:44:26,885 EPOCH 58 done: loss 0.6499 - lr 0.0015625\n",
            "2020-10-27 17:44:28,795 DEV : loss 2.135503053665161 - score 0.9148\n",
            "2020-10-27 17:44:28,844 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:44:28,845 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:44:32,331 epoch 59 - iter 25/254 - loss 0.62131015 - samples/sec: 229.67 - lr: 0.001563\n",
            "2020-10-27 17:44:35,553 epoch 59 - iter 50/254 - loss 0.65393834 - samples/sec: 248.56 - lr: 0.001563\n",
            "2020-10-27 17:44:38,777 epoch 59 - iter 75/254 - loss 0.64319395 - samples/sec: 248.32 - lr: 0.001563\n",
            "2020-10-27 17:44:42,100 epoch 59 - iter 100/254 - loss 0.64040872 - samples/sec: 241.03 - lr: 0.001563\n",
            "2020-10-27 17:44:45,298 epoch 59 - iter 125/254 - loss 0.63420525 - samples/sec: 250.44 - lr: 0.001563\n",
            "2020-10-27 17:44:48,458 epoch 59 - iter 150/254 - loss 0.62518684 - samples/sec: 253.52 - lr: 0.001563\n",
            "2020-10-27 17:44:51,837 epoch 59 - iter 175/254 - loss 0.62247814 - samples/sec: 236.96 - lr: 0.001563\n",
            "2020-10-27 17:44:54,974 epoch 59 - iter 200/254 - loss 0.62211443 - samples/sec: 255.30 - lr: 0.001563\n",
            "2020-10-27 17:44:58,244 epoch 59 - iter 225/254 - loss 0.61588147 - samples/sec: 244.81 - lr: 0.001563\n",
            "2020-10-27 17:45:01,693 epoch 59 - iter 250/254 - loss 0.62434872 - samples/sec: 232.15 - lr: 0.001563\n",
            "2020-10-27 17:45:02,118 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:45:02,119 EPOCH 59 done: loss 0.6240 - lr 0.0015625\n",
            "2020-10-27 17:45:04,492 DEV : loss 2.139446258544922 - score 0.9152\n",
            "2020-10-27 17:45:04,543 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:45:04,544 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:45:07,748 epoch 60 - iter 25/254 - loss 0.54415613 - samples/sec: 250.03 - lr: 0.001563\n",
            "2020-10-27 17:45:10,884 epoch 60 - iter 50/254 - loss 0.54603263 - samples/sec: 255.40 - lr: 0.001563\n",
            "2020-10-27 17:45:14,050 epoch 60 - iter 75/254 - loss 0.57969540 - samples/sec: 252.96 - lr: 0.001563\n",
            "2020-10-27 17:45:17,433 epoch 60 - iter 100/254 - loss 0.59609674 - samples/sec: 236.68 - lr: 0.001563\n",
            "2020-10-27 17:45:20,804 epoch 60 - iter 125/254 - loss 0.60430052 - samples/sec: 237.53 - lr: 0.001563\n",
            "2020-10-27 17:45:24,159 epoch 60 - iter 150/254 - loss 0.61007543 - samples/sec: 238.67 - lr: 0.001563\n",
            "2020-10-27 17:45:27,800 epoch 60 - iter 175/254 - loss 0.61622361 - samples/sec: 219.95 - lr: 0.001563\n",
            "2020-10-27 17:45:30,841 epoch 60 - iter 200/254 - loss 0.61085134 - samples/sec: 263.36 - lr: 0.001563\n",
            "2020-10-27 17:45:34,148 epoch 60 - iter 225/254 - loss 0.61692769 - samples/sec: 242.07 - lr: 0.001563\n",
            "2020-10-27 17:45:37,358 epoch 60 - iter 250/254 - loss 0.62292336 - samples/sec: 249.53 - lr: 0.001563\n",
            "2020-10-27 17:45:37,810 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:45:37,812 EPOCH 60 done: loss 0.6203 - lr 0.0015625\n",
            "2020-10-27 17:45:39,652 DEV : loss 2.142164707183838 - score 0.9147\n",
            "2020-10-27 17:45:39,699 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:45:39,700 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:45:42,941 epoch 61 - iter 25/254 - loss 0.61958024 - samples/sec: 247.14 - lr: 0.001563\n",
            "2020-10-27 17:45:46,305 epoch 61 - iter 50/254 - loss 0.60169972 - samples/sec: 238.00 - lr: 0.001563\n",
            "2020-10-27 17:45:49,460 epoch 61 - iter 75/254 - loss 0.61806597 - samples/sec: 253.83 - lr: 0.001563\n",
            "2020-10-27 17:45:52,714 epoch 61 - iter 100/254 - loss 0.63523926 - samples/sec: 246.05 - lr: 0.001563\n",
            "2020-10-27 17:45:56,061 epoch 61 - iter 125/254 - loss 0.63695495 - samples/sec: 239.20 - lr: 0.001563\n",
            "2020-10-27 17:45:59,457 epoch 61 - iter 150/254 - loss 0.62884635 - samples/sec: 235.79 - lr: 0.001563\n",
            "2020-10-27 17:46:02,903 epoch 61 - iter 175/254 - loss 0.63013533 - samples/sec: 232.35 - lr: 0.001563\n",
            "2020-10-27 17:46:06,170 epoch 61 - iter 200/254 - loss 0.62315264 - samples/sec: 245.18 - lr: 0.001563\n",
            "2020-10-27 17:46:09,304 epoch 61 - iter 225/254 - loss 0.61616313 - samples/sec: 255.57 - lr: 0.001563\n",
            "2020-10-27 17:46:12,452 epoch 61 - iter 250/254 - loss 0.61468532 - samples/sec: 254.40 - lr: 0.001563\n",
            "2020-10-27 17:46:13,012 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:46:13,015 EPOCH 61 done: loss 0.6162 - lr 0.0015625\n",
            "2020-10-27 17:46:14,897 DEV : loss 2.147146701812744 - score 0.9148\n",
            "Epoch    61: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2020-10-27 17:46:14,947 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:46:14,948 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:46:18,474 epoch 62 - iter 25/254 - loss 0.59263123 - samples/sec: 227.15 - lr: 0.000781\n",
            "2020-10-27 17:46:21,712 epoch 62 - iter 50/254 - loss 0.58053118 - samples/sec: 247.46 - lr: 0.000781\n",
            "2020-10-27 17:46:24,952 epoch 62 - iter 75/254 - loss 0.57681701 - samples/sec: 247.15 - lr: 0.000781\n",
            "2020-10-27 17:46:28,380 epoch 62 - iter 100/254 - loss 0.58906281 - samples/sec: 233.61 - lr: 0.000781\n",
            "2020-10-27 17:46:31,680 epoch 62 - iter 125/254 - loss 0.59963585 - samples/sec: 242.62 - lr: 0.000781\n",
            "2020-10-27 17:46:34,880 epoch 62 - iter 150/254 - loss 0.59568655 - samples/sec: 250.17 - lr: 0.000781\n",
            "2020-10-27 17:46:38,114 epoch 62 - iter 175/254 - loss 0.59632774 - samples/sec: 247.60 - lr: 0.000781\n",
            "2020-10-27 17:46:41,292 epoch 62 - iter 200/254 - loss 0.59578549 - samples/sec: 251.96 - lr: 0.000781\n",
            "2020-10-27 17:46:44,553 epoch 62 - iter 225/254 - loss 0.60473493 - samples/sec: 245.51 - lr: 0.000781\n",
            "2020-10-27 17:46:47,695 epoch 62 - iter 250/254 - loss 0.60922379 - samples/sec: 254.91 - lr: 0.000781\n",
            "2020-10-27 17:46:48,094 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:46:48,095 EPOCH 62 done: loss 0.6065 - lr 0.0007813\n",
            "2020-10-27 17:46:49,938 DEV : loss 2.1461663246154785 - score 0.9153\n",
            "2020-10-27 17:46:49,992 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:46:52,971 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:46:56,610 epoch 63 - iter 25/254 - loss 0.55456560 - samples/sec: 242.49 - lr: 0.000781\n",
            "2020-10-27 17:46:59,805 epoch 63 - iter 50/254 - loss 0.58934091 - samples/sec: 250.62 - lr: 0.000781\n",
            "2020-10-27 17:47:03,004 epoch 63 - iter 75/254 - loss 0.61692824 - samples/sec: 250.33 - lr: 0.000781\n",
            "2020-10-27 17:47:06,420 epoch 63 - iter 100/254 - loss 0.61465232 - samples/sec: 234.36 - lr: 0.000781\n",
            "2020-10-27 17:47:09,481 epoch 63 - iter 125/254 - loss 0.61663054 - samples/sec: 261.62 - lr: 0.000781\n",
            "2020-10-27 17:47:12,958 epoch 63 - iter 150/254 - loss 0.64095165 - samples/sec: 230.23 - lr: 0.000781\n",
            "2020-10-27 17:47:16,126 epoch 63 - iter 175/254 - loss 0.62969018 - samples/sec: 252.80 - lr: 0.000781\n",
            "2020-10-27 17:47:19,582 epoch 63 - iter 200/254 - loss 0.63574388 - samples/sec: 231.64 - lr: 0.000781\n",
            "2020-10-27 17:47:22,731 epoch 63 - iter 225/254 - loss 0.63141867 - samples/sec: 254.28 - lr: 0.000781\n",
            "2020-10-27 17:47:26,177 epoch 63 - iter 250/254 - loss 0.63159608 - samples/sec: 232.38 - lr: 0.000781\n",
            "2020-10-27 17:47:26,589 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:47:26,590 EPOCH 63 done: loss 0.6307 - lr 0.0007813\n",
            "2020-10-27 17:47:28,426 DEV : loss 2.1468253135681152 - score 0.9153\n",
            "2020-10-27 17:47:28,484 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:47:28,486 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:47:31,870 epoch 64 - iter 25/254 - loss 0.66491539 - samples/sec: 236.72 - lr: 0.000781\n",
            "2020-10-27 17:47:35,168 epoch 64 - iter 50/254 - loss 0.65867745 - samples/sec: 242.75 - lr: 0.000781\n",
            "2020-10-27 17:47:38,448 epoch 64 - iter 75/254 - loss 0.66675410 - samples/sec: 244.27 - lr: 0.000781\n",
            "2020-10-27 17:47:41,662 epoch 64 - iter 100/254 - loss 0.64368834 - samples/sec: 249.18 - lr: 0.000781\n",
            "2020-10-27 17:47:44,870 epoch 64 - iter 125/254 - loss 0.63182149 - samples/sec: 249.54 - lr: 0.000781\n",
            "2020-10-27 17:47:48,035 epoch 64 - iter 150/254 - loss 0.62508311 - samples/sec: 253.01 - lr: 0.000781\n",
            "2020-10-27 17:47:51,555 epoch 64 - iter 175/254 - loss 0.62836048 - samples/sec: 227.46 - lr: 0.000781\n",
            "2020-10-27 17:47:54,760 epoch 64 - iter 200/254 - loss 0.62492475 - samples/sec: 249.84 - lr: 0.000781\n",
            "2020-10-27 17:47:58,190 epoch 64 - iter 225/254 - loss 0.62069915 - samples/sec: 233.44 - lr: 0.000781\n",
            "2020-10-27 17:48:01,621 epoch 64 - iter 250/254 - loss 0.62126192 - samples/sec: 233.38 - lr: 0.000781\n",
            "2020-10-27 17:48:02,074 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:48:02,075 EPOCH 64 done: loss 0.6241 - lr 0.0007813\n",
            "2020-10-27 17:48:03,910 DEV : loss 2.1460421085357666 - score 0.9152\n",
            "2020-10-27 17:48:03,962 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:48:03,963 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:48:07,241 epoch 65 - iter 25/254 - loss 0.53259218 - samples/sec: 244.34 - lr: 0.000781\n",
            "2020-10-27 17:48:10,614 epoch 65 - iter 50/254 - loss 0.57452641 - samples/sec: 237.41 - lr: 0.000781\n",
            "2020-10-27 17:48:13,914 epoch 65 - iter 75/254 - loss 0.60954761 - samples/sec: 242.63 - lr: 0.000781\n",
            "2020-10-27 17:48:17,328 epoch 65 - iter 100/254 - loss 0.61895031 - samples/sec: 234.63 - lr: 0.000781\n",
            "2020-10-27 17:48:20,814 epoch 65 - iter 125/254 - loss 0.63653799 - samples/sec: 229.81 - lr: 0.000781\n",
            "2020-10-27 17:48:24,046 epoch 65 - iter 150/254 - loss 0.64971538 - samples/sec: 247.94 - lr: 0.000781\n",
            "2020-10-27 17:48:27,167 epoch 65 - iter 175/254 - loss 0.64711566 - samples/sec: 256.60 - lr: 0.000781\n",
            "2020-10-27 17:48:30,519 epoch 65 - iter 200/254 - loss 0.64135364 - samples/sec: 239.01 - lr: 0.000781\n",
            "2020-10-27 17:48:33,849 epoch 65 - iter 225/254 - loss 0.63268743 - samples/sec: 240.45 - lr: 0.000781\n",
            "2020-10-27 17:48:36,913 epoch 65 - iter 250/254 - loss 0.62602237 - samples/sec: 261.38 - lr: 0.000781\n",
            "2020-10-27 17:48:37,388 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:48:37,389 EPOCH 65 done: loss 0.6226 - lr 0.0007813\n",
            "2020-10-27 17:48:39,282 DEV : loss 2.1452109813690186 - score 0.9155\n",
            "2020-10-27 17:48:39,330 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:48:42,348 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:48:45,901 epoch 66 - iter 25/254 - loss 0.65451503 - samples/sec: 232.65 - lr: 0.000781\n",
            "2020-10-27 17:48:49,199 epoch 66 - iter 50/254 - loss 0.62395914 - samples/sec: 242.93 - lr: 0.000781\n",
            "2020-10-27 17:48:52,443 epoch 66 - iter 75/254 - loss 0.59035904 - samples/sec: 247.01 - lr: 0.000781\n",
            "2020-10-27 17:48:55,728 epoch 66 - iter 100/254 - loss 0.61382607 - samples/sec: 243.75 - lr: 0.000781\n",
            "2020-10-27 17:48:58,996 epoch 66 - iter 125/254 - loss 0.63609078 - samples/sec: 245.10 - lr: 0.000781\n",
            "2020-10-27 17:49:02,370 epoch 66 - iter 150/254 - loss 0.63212238 - samples/sec: 237.35 - lr: 0.000781\n",
            "2020-10-27 17:49:05,654 epoch 66 - iter 175/254 - loss 0.63533856 - samples/sec: 243.95 - lr: 0.000781\n",
            "2020-10-27 17:49:08,895 epoch 66 - iter 200/254 - loss 0.64098021 - samples/sec: 247.19 - lr: 0.000781\n",
            "2020-10-27 17:49:11,950 epoch 66 - iter 225/254 - loss 0.64018766 - samples/sec: 262.11 - lr: 0.000781\n",
            "2020-10-27 17:49:15,222 epoch 66 - iter 250/254 - loss 0.63725435 - samples/sec: 244.73 - lr: 0.000781\n",
            "2020-10-27 17:49:15,632 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:49:15,633 EPOCH 66 done: loss 0.6359 - lr 0.0007813\n",
            "2020-10-27 17:49:17,494 DEV : loss 2.14536452293396 - score 0.9155\n",
            "2020-10-27 17:49:17,547 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:49:17,551 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:49:20,887 epoch 67 - iter 25/254 - loss 0.63027181 - samples/sec: 240.07 - lr: 0.000781\n",
            "2020-10-27 17:49:24,244 epoch 67 - iter 50/254 - loss 0.65503440 - samples/sec: 238.65 - lr: 0.000781\n",
            "2020-10-27 17:49:27,501 epoch 67 - iter 75/254 - loss 0.62051042 - samples/sec: 245.86 - lr: 0.000781\n",
            "2020-10-27 17:49:30,776 epoch 67 - iter 100/254 - loss 0.61051945 - samples/sec: 244.63 - lr: 0.000781\n",
            "2020-10-27 17:49:33,962 epoch 67 - iter 125/254 - loss 0.60525730 - samples/sec: 251.31 - lr: 0.000781\n",
            "2020-10-27 17:49:37,481 epoch 67 - iter 150/254 - loss 0.60360264 - samples/sec: 227.51 - lr: 0.000781\n",
            "2020-10-27 17:49:40,598 epoch 67 - iter 175/254 - loss 0.61277414 - samples/sec: 256.90 - lr: 0.000781\n",
            "2020-10-27 17:49:43,836 epoch 67 - iter 200/254 - loss 0.60945455 - samples/sec: 247.31 - lr: 0.000781\n",
            "2020-10-27 17:49:47,019 epoch 67 - iter 225/254 - loss 0.60841132 - samples/sec: 251.74 - lr: 0.000781\n",
            "2020-10-27 17:49:50,509 epoch 67 - iter 250/254 - loss 0.61553056 - samples/sec: 229.43 - lr: 0.000781\n",
            "2020-10-27 17:49:51,010 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:49:51,011 EPOCH 67 done: loss 0.6163 - lr 0.0007813\n",
            "2020-10-27 17:49:52,873 DEV : loss 2.1489036083221436 - score 0.9147\n",
            "2020-10-27 17:49:52,924 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:49:52,925 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:49:56,553 epoch 68 - iter 25/254 - loss 0.59181410 - samples/sec: 220.82 - lr: 0.000781\n",
            "2020-10-27 17:49:59,856 epoch 68 - iter 50/254 - loss 0.60512711 - samples/sec: 242.52 - lr: 0.000781\n",
            "2020-10-27 17:50:03,035 epoch 68 - iter 75/254 - loss 0.60858075 - samples/sec: 251.85 - lr: 0.000781\n",
            "2020-10-27 17:50:06,524 epoch 68 - iter 100/254 - loss 0.61911796 - samples/sec: 229.50 - lr: 0.000781\n",
            "2020-10-27 17:50:09,829 epoch 68 - iter 125/254 - loss 0.60893774 - samples/sec: 242.43 - lr: 0.000781\n",
            "2020-10-27 17:50:13,116 epoch 68 - iter 150/254 - loss 0.60583249 - samples/sec: 243.62 - lr: 0.000781\n",
            "2020-10-27 17:50:16,277 epoch 68 - iter 175/254 - loss 0.61248797 - samples/sec: 253.51 - lr: 0.000781\n",
            "2020-10-27 17:50:19,556 epoch 68 - iter 200/254 - loss 0.61588341 - samples/sec: 244.23 - lr: 0.000781\n",
            "2020-10-27 17:50:22,996 epoch 68 - iter 225/254 - loss 0.61678884 - samples/sec: 232.85 - lr: 0.000781\n",
            "2020-10-27 17:50:26,349 epoch 68 - iter 250/254 - loss 0.61343574 - samples/sec: 238.80 - lr: 0.000781\n",
            "2020-10-27 17:50:26,800 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:50:26,801 EPOCH 68 done: loss 0.6115 - lr 0.0007813\n",
            "2020-10-27 17:50:28,653 DEV : loss 2.150651216506958 - score 0.9153\n",
            "2020-10-27 17:50:28,702 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:50:28,704 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:50:31,885 epoch 69 - iter 25/254 - loss 0.55415965 - samples/sec: 251.88 - lr: 0.000781\n",
            "2020-10-27 17:50:34,919 epoch 69 - iter 50/254 - loss 0.55474750 - samples/sec: 263.95 - lr: 0.000781\n",
            "2020-10-27 17:50:38,310 epoch 69 - iter 75/254 - loss 0.59599878 - samples/sec: 236.20 - lr: 0.000781\n",
            "2020-10-27 17:50:41,632 epoch 69 - iter 100/254 - loss 0.58345292 - samples/sec: 241.14 - lr: 0.000781\n",
            "2020-10-27 17:50:45,113 epoch 69 - iter 125/254 - loss 0.58222754 - samples/sec: 230.09 - lr: 0.000781\n",
            "2020-10-27 17:50:48,353 epoch 69 - iter 150/254 - loss 0.58106449 - samples/sec: 247.06 - lr: 0.000781\n",
            "2020-10-27 17:50:51,616 epoch 69 - iter 175/254 - loss 0.58208022 - samples/sec: 245.45 - lr: 0.000781\n",
            "2020-10-27 17:50:54,919 epoch 69 - iter 200/254 - loss 0.59010568 - samples/sec: 242.57 - lr: 0.000781\n",
            "2020-10-27 17:50:58,139 epoch 69 - iter 225/254 - loss 0.60369937 - samples/sec: 248.67 - lr: 0.000781\n",
            "2020-10-27 17:51:01,305 epoch 69 - iter 250/254 - loss 0.60192827 - samples/sec: 252.88 - lr: 0.000781\n",
            "2020-10-27 17:51:01,709 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:51:01,710 EPOCH 69 done: loss 0.5989 - lr 0.0007813\n",
            "2020-10-27 17:51:03,568 DEV : loss 2.1507949829101562 - score 0.915\n",
            "Epoch    69: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2020-10-27 17:51:03,618 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:51:03,619 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:51:06,877 epoch 70 - iter 25/254 - loss 0.63557468 - samples/sec: 245.86 - lr: 0.000391\n",
            "2020-10-27 17:51:10,212 epoch 70 - iter 50/254 - loss 0.64336315 - samples/sec: 240.06 - lr: 0.000391\n",
            "2020-10-27 17:51:13,492 epoch 70 - iter 75/254 - loss 0.62942245 - samples/sec: 244.58 - lr: 0.000391\n",
            "2020-10-27 17:51:16,672 epoch 70 - iter 100/254 - loss 0.63006709 - samples/sec: 251.82 - lr: 0.000391\n",
            "2020-10-27 17:51:20,102 epoch 70 - iter 125/254 - loss 0.63639823 - samples/sec: 233.43 - lr: 0.000391\n",
            "2020-10-27 17:51:23,242 epoch 70 - iter 150/254 - loss 0.62693051 - samples/sec: 255.11 - lr: 0.000391\n",
            "2020-10-27 17:51:26,446 epoch 70 - iter 175/254 - loss 0.62418598 - samples/sec: 249.94 - lr: 0.000391\n",
            "2020-10-27 17:51:29,638 epoch 70 - iter 200/254 - loss 0.62264814 - samples/sec: 250.78 - lr: 0.000391\n",
            "2020-10-27 17:51:33,026 epoch 70 - iter 225/254 - loss 0.62704731 - samples/sec: 236.32 - lr: 0.000391\n",
            "2020-10-27 17:51:36,338 epoch 70 - iter 250/254 - loss 0.62243036 - samples/sec: 241.82 - lr: 0.000391\n",
            "2020-10-27 17:51:36,713 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:51:36,714 EPOCH 70 done: loss 0.6181 - lr 0.0003906\n",
            "2020-10-27 17:51:38,589 DEV : loss 2.149679660797119 - score 0.9149\n",
            "2020-10-27 17:51:38,639 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:51:38,640 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:51:41,990 epoch 71 - iter 25/254 - loss 0.59667553 - samples/sec: 239.16 - lr: 0.000391\n",
            "2020-10-27 17:51:45,262 epoch 71 - iter 50/254 - loss 0.62857719 - samples/sec: 244.90 - lr: 0.000391\n",
            "2020-10-27 17:51:48,697 epoch 71 - iter 75/254 - loss 0.63174828 - samples/sec: 233.04 - lr: 0.000391\n",
            "2020-10-27 17:51:52,171 epoch 71 - iter 100/254 - loss 0.63707114 - samples/sec: 230.51 - lr: 0.000391\n",
            "2020-10-27 17:51:55,426 epoch 71 - iter 125/254 - loss 0.64155438 - samples/sec: 246.11 - lr: 0.000391\n",
            "2020-10-27 17:51:58,557 epoch 71 - iter 150/254 - loss 0.62799927 - samples/sec: 255.91 - lr: 0.000391\n",
            "2020-10-27 17:52:01,864 epoch 71 - iter 175/254 - loss 0.62291060 - samples/sec: 242.12 - lr: 0.000391\n",
            "2020-10-27 17:52:05,081 epoch 71 - iter 200/254 - loss 0.62049875 - samples/sec: 248.85 - lr: 0.000391\n",
            "2020-10-27 17:52:08,169 epoch 71 - iter 225/254 - loss 0.61913466 - samples/sec: 259.46 - lr: 0.000391\n",
            "2020-10-27 17:52:11,432 epoch 71 - iter 250/254 - loss 0.61195646 - samples/sec: 245.39 - lr: 0.000391\n",
            "2020-10-27 17:52:11,864 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:52:11,865 EPOCH 71 done: loss 0.6145 - lr 0.0003906\n",
            "2020-10-27 17:52:13,753 DEV : loss 2.150007963180542 - score 0.9149\n",
            "2020-10-27 17:52:13,801 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:52:13,802 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:52:16,996 epoch 72 - iter 25/254 - loss 0.58843554 - samples/sec: 250.82 - lr: 0.000391\n",
            "2020-10-27 17:52:20,129 epoch 72 - iter 50/254 - loss 0.62012556 - samples/sec: 255.65 - lr: 0.000391\n",
            "2020-10-27 17:52:23,193 epoch 72 - iter 75/254 - loss 0.60887348 - samples/sec: 261.47 - lr: 0.000391\n",
            "2020-10-27 17:52:26,405 epoch 72 - iter 100/254 - loss 0.61301885 - samples/sec: 249.25 - lr: 0.000391\n",
            "2020-10-27 17:52:29,710 epoch 72 - iter 125/254 - loss 0.60929548 - samples/sec: 242.32 - lr: 0.000391\n",
            "2020-10-27 17:52:33,053 epoch 72 - iter 150/254 - loss 0.61986310 - samples/sec: 239.53 - lr: 0.000391\n",
            "2020-10-27 17:52:36,420 epoch 72 - iter 175/254 - loss 0.62168819 - samples/sec: 237.82 - lr: 0.000391\n",
            "2020-10-27 17:52:39,734 epoch 72 - iter 200/254 - loss 0.61729889 - samples/sec: 241.60 - lr: 0.000391\n",
            "2020-10-27 17:52:43,113 epoch 72 - iter 225/254 - loss 0.61804968 - samples/sec: 237.13 - lr: 0.000391\n",
            "2020-10-27 17:52:46,414 epoch 72 - iter 250/254 - loss 0.62598211 - samples/sec: 242.59 - lr: 0.000391\n",
            "2020-10-27 17:52:46,893 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:52:46,894 EPOCH 72 done: loss 0.6273 - lr 0.0003906\n",
            "2020-10-27 17:52:48,747 DEV : loss 2.147437334060669 - score 0.9157\n",
            "2020-10-27 17:52:48,801 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:52:51,930 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:52:55,210 epoch 73 - iter 25/254 - loss 0.54851674 - samples/sec: 244.24 - lr: 0.000391\n",
            "2020-10-27 17:52:58,361 epoch 73 - iter 50/254 - loss 0.59817792 - samples/sec: 254.13 - lr: 0.000391\n",
            "2020-10-27 17:53:01,550 epoch 73 - iter 75/254 - loss 0.61021774 - samples/sec: 251.09 - lr: 0.000391\n",
            "2020-10-27 17:53:04,733 epoch 73 - iter 100/254 - loss 0.60398899 - samples/sec: 251.89 - lr: 0.000391\n",
            "2020-10-27 17:53:08,031 epoch 73 - iter 125/254 - loss 0.59710124 - samples/sec: 242.76 - lr: 0.000391\n",
            "2020-10-27 17:53:11,358 epoch 73 - iter 150/254 - loss 0.60754006 - samples/sec: 240.72 - lr: 0.000391\n",
            "2020-10-27 17:53:14,675 epoch 73 - iter 175/254 - loss 0.60759386 - samples/sec: 241.46 - lr: 0.000391\n",
            "2020-10-27 17:53:18,101 epoch 73 - iter 200/254 - loss 0.61094579 - samples/sec: 233.70 - lr: 0.000391\n",
            "2020-10-27 17:53:21,444 epoch 73 - iter 225/254 - loss 0.60945345 - samples/sec: 239.49 - lr: 0.000391\n",
            "2020-10-27 17:53:24,795 epoch 73 - iter 250/254 - loss 0.62182768 - samples/sec: 238.97 - lr: 0.000391\n",
            "2020-10-27 17:53:25,270 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:53:25,271 EPOCH 73 done: loss 0.6229 - lr 0.0003906\n",
            "2020-10-27 17:53:27,118 DEV : loss 2.1488280296325684 - score 0.915\n",
            "2020-10-27 17:53:27,165 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:53:27,167 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:53:30,507 epoch 74 - iter 25/254 - loss 0.58774958 - samples/sec: 239.84 - lr: 0.000391\n",
            "2020-10-27 17:53:33,839 epoch 74 - iter 50/254 - loss 0.57722515 - samples/sec: 240.28 - lr: 0.000391\n",
            "2020-10-27 17:53:37,202 epoch 74 - iter 75/254 - loss 0.60842745 - samples/sec: 238.16 - lr: 0.000391\n",
            "2020-10-27 17:53:40,457 epoch 74 - iter 100/254 - loss 0.60582160 - samples/sec: 246.05 - lr: 0.000391\n",
            "2020-10-27 17:53:43,798 epoch 74 - iter 125/254 - loss 0.61637980 - samples/sec: 239.72 - lr: 0.000391\n",
            "2020-10-27 17:53:47,153 epoch 74 - iter 150/254 - loss 0.62685480 - samples/sec: 238.66 - lr: 0.000391\n",
            "2020-10-27 17:53:50,310 epoch 74 - iter 175/254 - loss 0.62387474 - samples/sec: 253.68 - lr: 0.000391\n",
            "2020-10-27 17:53:53,699 epoch 74 - iter 200/254 - loss 0.61776863 - samples/sec: 236.20 - lr: 0.000391\n",
            "2020-10-27 17:53:56,972 epoch 74 - iter 225/254 - loss 0.61183736 - samples/sec: 244.68 - lr: 0.000391\n",
            "2020-10-27 17:54:00,247 epoch 74 - iter 250/254 - loss 0.61699332 - samples/sec: 244.46 - lr: 0.000391\n",
            "2020-10-27 17:54:00,675 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:54:00,676 EPOCH 74 done: loss 0.6242 - lr 0.0003906\n",
            "2020-10-27 17:54:02,539 DEV : loss 2.1486401557922363 - score 0.9154\n",
            "2020-10-27 17:54:02,588 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:54:02,589 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:54:06,066 epoch 75 - iter 25/254 - loss 0.63515581 - samples/sec: 230.34 - lr: 0.000391\n",
            "2020-10-27 17:54:09,327 epoch 75 - iter 50/254 - loss 0.60844097 - samples/sec: 245.61 - lr: 0.000391\n",
            "2020-10-27 17:54:12,448 epoch 75 - iter 75/254 - loss 0.60125305 - samples/sec: 256.50 - lr: 0.000391\n",
            "2020-10-27 17:54:16,089 epoch 75 - iter 100/254 - loss 0.59415851 - samples/sec: 219.95 - lr: 0.000391\n",
            "2020-10-27 17:54:19,285 epoch 75 - iter 125/254 - loss 0.59817781 - samples/sec: 250.66 - lr: 0.000391\n",
            "2020-10-27 17:54:22,657 epoch 75 - iter 150/254 - loss 0.60426177 - samples/sec: 237.54 - lr: 0.000391\n",
            "2020-10-27 17:54:25,849 epoch 75 - iter 175/254 - loss 0.61270148 - samples/sec: 250.93 - lr: 0.000391\n",
            "2020-10-27 17:54:29,019 epoch 75 - iter 200/254 - loss 0.61721072 - samples/sec: 252.70 - lr: 0.000391\n",
            "2020-10-27 17:54:32,286 epoch 75 - iter 225/254 - loss 0.60933702 - samples/sec: 245.09 - lr: 0.000391\n",
            "2020-10-27 17:54:35,539 epoch 75 - iter 250/254 - loss 0.61279280 - samples/sec: 246.19 - lr: 0.000391\n",
            "2020-10-27 17:54:36,019 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:54:36,020 EPOCH 75 done: loss 0.6099 - lr 0.0003906\n",
            "2020-10-27 17:54:37,892 DEV : loss 2.1473445892333984 - score 0.9155\n",
            "2020-10-27 17:54:37,942 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:54:37,944 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:54:41,177 epoch 76 - iter 25/254 - loss 0.59610598 - samples/sec: 247.73 - lr: 0.000391\n",
            "2020-10-27 17:54:44,644 epoch 76 - iter 50/254 - loss 0.63886560 - samples/sec: 230.97 - lr: 0.000391\n",
            "2020-10-27 17:54:47,945 epoch 76 - iter 75/254 - loss 0.64026272 - samples/sec: 242.55 - lr: 0.000391\n",
            "2020-10-27 17:54:51,223 epoch 76 - iter 100/254 - loss 0.62148645 - samples/sec: 244.25 - lr: 0.000391\n",
            "2020-10-27 17:54:54,597 epoch 76 - iter 125/254 - loss 0.62177968 - samples/sec: 237.43 - lr: 0.000391\n",
            "2020-10-27 17:54:57,744 epoch 76 - iter 150/254 - loss 0.63026127 - samples/sec: 254.50 - lr: 0.000391\n",
            "2020-10-27 17:55:01,084 epoch 76 - iter 175/254 - loss 0.62631318 - samples/sec: 239.83 - lr: 0.000391\n",
            "2020-10-27 17:55:04,322 epoch 76 - iter 200/254 - loss 0.62032092 - samples/sec: 247.23 - lr: 0.000391\n",
            "2020-10-27 17:55:07,618 epoch 76 - iter 225/254 - loss 0.62099505 - samples/sec: 243.07 - lr: 0.000391\n",
            "2020-10-27 17:55:10,885 epoch 76 - iter 250/254 - loss 0.62228686 - samples/sec: 245.06 - lr: 0.000391\n",
            "2020-10-27 17:55:11,358 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:55:11,359 EPOCH 76 done: loss 0.6223 - lr 0.0003906\n",
            "2020-10-27 17:55:13,741 DEV : loss 2.1475751399993896 - score 0.9153\n",
            "Epoch    76: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2020-10-27 17:55:13,790 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:55:13,792 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:55:17,050 epoch 77 - iter 25/254 - loss 0.56509256 - samples/sec: 245.84 - lr: 0.000195\n",
            "2020-10-27 17:55:20,356 epoch 77 - iter 50/254 - loss 0.56556938 - samples/sec: 242.20 - lr: 0.000195\n",
            "2020-10-27 17:55:24,103 epoch 77 - iter 75/254 - loss 0.57666499 - samples/sec: 213.70 - lr: 0.000195\n",
            "2020-10-27 17:55:27,314 epoch 77 - iter 100/254 - loss 0.58450184 - samples/sec: 249.37 - lr: 0.000195\n",
            "2020-10-27 17:55:30,743 epoch 77 - iter 125/254 - loss 0.60268409 - samples/sec: 233.45 - lr: 0.000195\n",
            "2020-10-27 17:55:33,976 epoch 77 - iter 150/254 - loss 0.60441633 - samples/sec: 247.74 - lr: 0.000195\n",
            "2020-10-27 17:55:37,062 epoch 77 - iter 175/254 - loss 0.60412391 - samples/sec: 259.60 - lr: 0.000195\n",
            "2020-10-27 17:55:40,225 epoch 77 - iter 200/254 - loss 0.61312398 - samples/sec: 253.23 - lr: 0.000195\n",
            "2020-10-27 17:55:43,423 epoch 77 - iter 225/254 - loss 0.61998839 - samples/sec: 250.48 - lr: 0.000195\n",
            "2020-10-27 17:55:46,654 epoch 77 - iter 250/254 - loss 0.61795560 - samples/sec: 247.83 - lr: 0.000195\n",
            "2020-10-27 17:55:47,068 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:55:47,070 EPOCH 77 done: loss 0.6162 - lr 0.0001953\n",
            "2020-10-27 17:55:48,905 DEV : loss 2.1478464603424072 - score 0.915\n",
            "2020-10-27 17:55:48,953 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:55:48,954 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:55:52,120 epoch 78 - iter 25/254 - loss 0.52731552 - samples/sec: 252.98 - lr: 0.000195\n",
            "2020-10-27 17:55:55,396 epoch 78 - iter 50/254 - loss 0.60636871 - samples/sec: 244.54 - lr: 0.000195\n",
            "2020-10-27 17:55:58,530 epoch 78 - iter 75/254 - loss 0.60968896 - samples/sec: 255.59 - lr: 0.000195\n",
            "2020-10-27 17:56:01,856 epoch 78 - iter 100/254 - loss 0.62693451 - samples/sec: 240.74 - lr: 0.000195\n",
            "2020-10-27 17:56:04,936 epoch 78 - iter 125/254 - loss 0.63997321 - samples/sec: 260.07 - lr: 0.000195\n",
            "2020-10-27 17:56:08,193 epoch 78 - iter 150/254 - loss 0.62575186 - samples/sec: 245.89 - lr: 0.000195\n",
            "2020-10-27 17:56:11,558 epoch 78 - iter 175/254 - loss 0.62427787 - samples/sec: 238.05 - lr: 0.000195\n",
            "2020-10-27 17:56:14,935 epoch 78 - iter 200/254 - loss 0.62315761 - samples/sec: 237.08 - lr: 0.000195\n",
            "2020-10-27 17:56:18,155 epoch 78 - iter 225/254 - loss 0.61837634 - samples/sec: 248.83 - lr: 0.000195\n",
            "2020-10-27 17:56:21,552 epoch 78 - iter 250/254 - loss 0.61960348 - samples/sec: 235.68 - lr: 0.000195\n",
            "2020-10-27 17:56:22,008 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:56:22,009 EPOCH 78 done: loss 0.6225 - lr 0.0001953\n",
            "2020-10-27 17:56:23,838 DEV : loss 2.1476922035217285 - score 0.9151\n",
            "2020-10-27 17:56:23,889 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:56:23,889 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:56:27,166 epoch 79 - iter 25/254 - loss 0.53178728 - samples/sec: 244.42 - lr: 0.000195\n",
            "2020-10-27 17:56:30,648 epoch 79 - iter 50/254 - loss 0.58443058 - samples/sec: 229.98 - lr: 0.000195\n",
            "2020-10-27 17:56:34,042 epoch 79 - iter 75/254 - loss 0.59437290 - samples/sec: 236.04 - lr: 0.000195\n",
            "2020-10-27 17:56:37,248 epoch 79 - iter 100/254 - loss 0.60242075 - samples/sec: 249.76 - lr: 0.000195\n",
            "2020-10-27 17:56:40,451 epoch 79 - iter 125/254 - loss 0.60473780 - samples/sec: 249.94 - lr: 0.000195\n",
            "2020-10-27 17:56:43,677 epoch 79 - iter 150/254 - loss 0.60763562 - samples/sec: 248.23 - lr: 0.000195\n",
            "2020-10-27 17:56:47,021 epoch 79 - iter 175/254 - loss 0.61815686 - samples/sec: 239.45 - lr: 0.000195\n",
            "2020-10-27 17:56:50,082 epoch 79 - iter 200/254 - loss 0.61480312 - samples/sec: 261.57 - lr: 0.000195\n",
            "2020-10-27 17:56:53,427 epoch 79 - iter 225/254 - loss 0.61541606 - samples/sec: 239.36 - lr: 0.000195\n",
            "2020-10-27 17:56:56,758 epoch 79 - iter 250/254 - loss 0.61445018 - samples/sec: 240.44 - lr: 0.000195\n",
            "2020-10-27 17:56:57,179 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:56:57,180 EPOCH 79 done: loss 0.6116 - lr 0.0001953\n",
            "2020-10-27 17:56:59,047 DEV : loss 2.1466970443725586 - score 0.9155\n",
            "2020-10-27 17:56:59,100 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:56:59,101 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:57:02,308 epoch 80 - iter 25/254 - loss 0.57937304 - samples/sec: 249.80 - lr: 0.000195\n",
            "2020-10-27 17:57:05,629 epoch 80 - iter 50/254 - loss 0.59908437 - samples/sec: 241.06 - lr: 0.000195\n",
            "2020-10-27 17:57:08,889 epoch 80 - iter 75/254 - loss 0.60647793 - samples/sec: 245.77 - lr: 0.000195\n",
            "2020-10-27 17:57:12,023 epoch 80 - iter 100/254 - loss 0.59225243 - samples/sec: 255.63 - lr: 0.000195\n",
            "2020-10-27 17:57:15,274 epoch 80 - iter 125/254 - loss 0.58213498 - samples/sec: 246.44 - lr: 0.000195\n",
            "2020-10-27 17:57:18,391 epoch 80 - iter 150/254 - loss 0.58114171 - samples/sec: 256.89 - lr: 0.000195\n",
            "2020-10-27 17:57:21,748 epoch 80 - iter 175/254 - loss 0.59275038 - samples/sec: 238.49 - lr: 0.000195\n",
            "2020-10-27 17:57:24,870 epoch 80 - iter 200/254 - loss 0.59162087 - samples/sec: 256.48 - lr: 0.000195\n",
            "2020-10-27 17:57:28,366 epoch 80 - iter 225/254 - loss 0.59960735 - samples/sec: 229.02 - lr: 0.000195\n",
            "2020-10-27 17:57:31,690 epoch 80 - iter 250/254 - loss 0.59913326 - samples/sec: 240.93 - lr: 0.000195\n",
            "2020-10-27 17:57:32,191 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:57:32,193 EPOCH 80 done: loss 0.6017 - lr 0.0001953\n",
            "2020-10-27 17:57:34,051 DEV : loss 2.146906852722168 - score 0.9158\n",
            "2020-10-27 17:57:34,100 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-10-27 17:57:37,085 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:57:40,584 epoch 81 - iter 25/254 - loss 0.64532623 - samples/sec: 229.47 - lr: 0.000195\n",
            "2020-10-27 17:57:43,715 epoch 81 - iter 50/254 - loss 0.64186804 - samples/sec: 255.72 - lr: 0.000195\n",
            "2020-10-27 17:57:47,076 epoch 81 - iter 75/254 - loss 0.64876189 - samples/sec: 238.29 - lr: 0.000195\n",
            "2020-10-27 17:57:50,556 epoch 81 - iter 100/254 - loss 0.65483801 - samples/sec: 230.20 - lr: 0.000195\n",
            "2020-10-27 17:57:53,757 epoch 81 - iter 125/254 - loss 0.65266300 - samples/sec: 250.14 - lr: 0.000195\n",
            "2020-10-27 17:57:57,127 epoch 81 - iter 150/254 - loss 0.63826277 - samples/sec: 237.61 - lr: 0.000195\n",
            "2020-10-27 17:58:00,637 epoch 81 - iter 175/254 - loss 0.64061162 - samples/sec: 228.06 - lr: 0.000195\n",
            "2020-10-27 17:58:03,639 epoch 81 - iter 200/254 - loss 0.63488434 - samples/sec: 266.82 - lr: 0.000195\n",
            "2020-10-27 17:58:06,805 epoch 81 - iter 225/254 - loss 0.62024878 - samples/sec: 252.91 - lr: 0.000195\n",
            "2020-10-27 17:58:10,069 epoch 81 - iter 250/254 - loss 0.61778528 - samples/sec: 245.30 - lr: 0.000195\n",
            "2020-10-27 17:58:10,538 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:58:10,540 EPOCH 81 done: loss 0.6210 - lr 0.0001953\n",
            "2020-10-27 17:58:12,394 DEV : loss 2.147050142288208 - score 0.9158\n",
            "2020-10-27 17:58:12,444 BAD EPOCHS (no improvement): 1\n",
            "2020-10-27 17:58:12,445 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:58:15,752 epoch 82 - iter 25/254 - loss 0.56227497 - samples/sec: 242.23 - lr: 0.000195\n",
            "2020-10-27 17:58:19,120 epoch 82 - iter 50/254 - loss 0.56271253 - samples/sec: 237.86 - lr: 0.000195\n",
            "2020-10-27 17:58:22,373 epoch 82 - iter 75/254 - loss 0.58001394 - samples/sec: 246.13 - lr: 0.000195\n",
            "2020-10-27 17:58:25,568 epoch 82 - iter 100/254 - loss 0.57205607 - samples/sec: 250.61 - lr: 0.000195\n",
            "2020-10-27 17:58:28,867 epoch 82 - iter 125/254 - loss 0.57900034 - samples/sec: 242.88 - lr: 0.000195\n",
            "2020-10-27 17:58:32,066 epoch 82 - iter 150/254 - loss 0.57841570 - samples/sec: 250.32 - lr: 0.000195\n",
            "2020-10-27 17:58:35,380 epoch 82 - iter 175/254 - loss 0.57384673 - samples/sec: 241.62 - lr: 0.000195\n",
            "2020-10-27 17:58:38,533 epoch 82 - iter 200/254 - loss 0.57242942 - samples/sec: 253.98 - lr: 0.000195\n",
            "2020-10-27 17:58:41,774 epoch 82 - iter 225/254 - loss 0.57504043 - samples/sec: 247.05 - lr: 0.000195\n",
            "2020-10-27 17:58:45,095 epoch 82 - iter 250/254 - loss 0.57833164 - samples/sec: 241.12 - lr: 0.000195\n",
            "2020-10-27 17:58:45,620 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:58:45,621 EPOCH 82 done: loss 0.5791 - lr 0.0001953\n",
            "2020-10-27 17:58:47,547 DEV : loss 2.147470712661743 - score 0.9158\n",
            "2020-10-27 17:58:47,596 BAD EPOCHS (no improvement): 2\n",
            "2020-10-27 17:58:47,597 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:58:50,985 epoch 83 - iter 25/254 - loss 0.60151539 - samples/sec: 236.46 - lr: 0.000195\n",
            "2020-10-27 17:58:54,410 epoch 83 - iter 50/254 - loss 0.60446335 - samples/sec: 233.80 - lr: 0.000195\n",
            "2020-10-27 17:58:57,609 epoch 83 - iter 75/254 - loss 0.60064267 - samples/sec: 250.41 - lr: 0.000195\n",
            "2020-10-27 17:59:00,953 epoch 83 - iter 100/254 - loss 0.59319951 - samples/sec: 239.51 - lr: 0.000195\n",
            "2020-10-27 17:59:04,231 epoch 83 - iter 125/254 - loss 0.59219082 - samples/sec: 244.26 - lr: 0.000195\n",
            "2020-10-27 17:59:07,365 epoch 83 - iter 150/254 - loss 0.59134454 - samples/sec: 255.52 - lr: 0.000195\n",
            "2020-10-27 17:59:10,451 epoch 83 - iter 175/254 - loss 0.58885308 - samples/sec: 259.64 - lr: 0.000195\n",
            "2020-10-27 17:59:13,722 epoch 83 - iter 200/254 - loss 0.59463883 - samples/sec: 244.74 - lr: 0.000195\n",
            "2020-10-27 17:59:17,199 epoch 83 - iter 225/254 - loss 0.60433981 - samples/sec: 230.33 - lr: 0.000195\n",
            "2020-10-27 17:59:20,545 epoch 83 - iter 250/254 - loss 0.60208932 - samples/sec: 239.26 - lr: 0.000195\n",
            "2020-10-27 17:59:21,014 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:59:21,015 EPOCH 83 done: loss 0.6000 - lr 0.0001953\n",
            "2020-10-27 17:59:22,844 DEV : loss 2.148437976837158 - score 0.9155\n",
            "2020-10-27 17:59:22,892 BAD EPOCHS (no improvement): 3\n",
            "2020-10-27 17:59:22,893 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:59:26,184 epoch 84 - iter 25/254 - loss 0.65120382 - samples/sec: 243.72 - lr: 0.000195\n",
            "2020-10-27 17:59:29,578 epoch 84 - iter 50/254 - loss 0.64334476 - samples/sec: 235.92 - lr: 0.000195\n",
            "2020-10-27 17:59:32,751 epoch 84 - iter 75/254 - loss 0.61038098 - samples/sec: 252.37 - lr: 0.000195\n",
            "2020-10-27 17:59:35,917 epoch 84 - iter 100/254 - loss 0.60297956 - samples/sec: 252.90 - lr: 0.000195\n",
            "2020-10-27 17:59:39,419 epoch 84 - iter 125/254 - loss 0.61282125 - samples/sec: 228.68 - lr: 0.000195\n",
            "2020-10-27 17:59:42,528 epoch 84 - iter 150/254 - loss 0.61682833 - samples/sec: 257.54 - lr: 0.000195\n",
            "2020-10-27 17:59:45,943 epoch 84 - iter 175/254 - loss 0.60740623 - samples/sec: 234.50 - lr: 0.000195\n",
            "2020-10-27 17:59:49,083 epoch 84 - iter 200/254 - loss 0.60004183 - samples/sec: 254.98 - lr: 0.000195\n",
            "2020-10-27 17:59:52,370 epoch 84 - iter 225/254 - loss 0.60181128 - samples/sec: 243.58 - lr: 0.000195\n",
            "2020-10-27 17:59:55,594 epoch 84 - iter 250/254 - loss 0.59779052 - samples/sec: 248.39 - lr: 0.000195\n",
            "2020-10-27 17:59:55,974 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:59:55,975 EPOCH 84 done: loss 0.5970 - lr 0.0001953\n",
            "2020-10-27 17:59:58,263 DEV : loss 2.148599147796631 - score 0.9154\n",
            "Epoch    84: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2020-10-27 17:59:58,314 BAD EPOCHS (no improvement): 4\n",
            "2020-10-27 17:59:58,316 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:59:58,317 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 17:59:58,318 learning rate too small - quitting training!\n",
            "2020-10-27 17:59:58,318 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 18:00:01,245 ----------------------------------------------------------------------------------------------------\n",
            "2020-10-27 18:00:01,246 Testing using best model ...\n",
            "2020-10-27 18:00:01,455 loading file resources/taggers/example-ner/best-model.pt\n",
            "2020-10-27 18:00:23,965 0.9104\t0.9116\t0.9110\n",
            "2020-10-27 18:00:23,966 \n",
            "Results:\n",
            "- F1-score (micro) 0.9110\n",
            "- F1-score (macro) 0.8885\n",
            "\n",
            "By class:\n",
            "DATE       tp: 73 - fp: 12 - fn: 10 - precision: 0.8588 - recall: 0.8795 - f1-score: 0.8690\n",
            "EVENT      tp: 1283 - fp: 174 - fn: 198 - precision: 0.8806 - recall: 0.8663 - f1-score: 0.8734\n",
            "JINMEI     tp: 618 - fp: 59 - fn: 52 - precision: 0.9129 - recall: 0.9224 - f1-score: 0.9176\n",
            "PLACE      tp: 410 - fp: 51 - fn: 49 - precision: 0.8894 - recall: 0.8932 - f1-score: 0.8913\n",
            "QUANTITY   tp: 106 - fp: 22 - fn: 24 - precision: 0.8281 - recall: 0.8154 - f1-score: 0.8217\n",
            "ROLE       tp: 546 - fp: 87 - fn: 70 - precision: 0.8626 - recall: 0.8864 - f1-score: 0.8743\n",
            "TERMS      tp: 1554 - fp: 47 - fn: 42 - precision: 0.9706 - recall: 0.9737 - f1-score: 0.9722\n",
            "2020-10-27 18:00:23,966 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [5.599512577056885,\n",
              "  4.080484390258789,\n",
              "  3.3933682441711426,\n",
              "  3.063971757888794,\n",
              "  2.8310115337371826,\n",
              "  2.7357428073883057,\n",
              "  2.4002184867858887,\n",
              "  2.4102425575256348,\n",
              "  2.4524059295654297,\n",
              "  2.1729090213775635,\n",
              "  2.260093927383423,\n",
              "  2.155740976333618,\n",
              "  2.0907511711120605,\n",
              "  2.072341203689575,\n",
              "  2.0636537075042725,\n",
              "  2.0752480030059814,\n",
              "  2.053154230117798,\n",
              "  2.003392457962036,\n",
              "  2.009709119796753,\n",
              "  1.9953813552856445,\n",
              "  2.0428969860076904,\n",
              "  1.980286955833435,\n",
              "  1.9705686569213867,\n",
              "  1.9890930652618408,\n",
              "  1.9748477935791016,\n",
              "  2.018021583557129,\n",
              "  2.0003604888916016,\n",
              "  2.056325674057007,\n",
              "  2.036849021911621,\n",
              "  2.0409984588623047,\n",
              "  1.9902448654174805,\n",
              "  1.9912399053573608,\n",
              "  1.946303367614746,\n",
              "  2.0211832523345947,\n",
              "  2.036879062652588,\n",
              "  2.022401809692383,\n",
              "  2.088564157485962,\n",
              "  2.088327646255493,\n",
              "  2.060406446456909,\n",
              "  2.083144426345825,\n",
              "  2.0058534145355225,\n",
              "  2.0916855335235596,\n",
              "  2.104879140853882,\n",
              "  2.0932247638702393,\n",
              "  2.144139289855957,\n",
              "  2.112075090408325,\n",
              "  2.114677667617798,\n",
              "  2.133408546447754,\n",
              "  2.138373374938965,\n",
              "  2.1326441764831543,\n",
              "  2.121055841445923,\n",
              "  2.1321651935577393,\n",
              "  2.1426899433135986,\n",
              "  2.1328184604644775,\n",
              "  2.137350082397461,\n",
              "  2.134869337081909,\n",
              "  2.135572910308838,\n",
              "  2.135503053665161,\n",
              "  2.139446258544922,\n",
              "  2.142164707183838,\n",
              "  2.147146701812744,\n",
              "  2.1461663246154785,\n",
              "  2.1468253135681152,\n",
              "  2.1460421085357666,\n",
              "  2.1452109813690186,\n",
              "  2.14536452293396,\n",
              "  2.1489036083221436,\n",
              "  2.150651216506958,\n",
              "  2.1507949829101562,\n",
              "  2.149679660797119,\n",
              "  2.150007963180542,\n",
              "  2.147437334060669,\n",
              "  2.1488280296325684,\n",
              "  2.1486401557922363,\n",
              "  2.1473445892333984,\n",
              "  2.1475751399993896,\n",
              "  2.1478464603424072,\n",
              "  2.1476922035217285,\n",
              "  2.1466970443725586,\n",
              "  2.146906852722168,\n",
              "  2.147050142288208,\n",
              "  2.147470712661743,\n",
              "  2.148437976837158,\n",
              "  2.148599147796631],\n",
              " 'dev_score_history': [0.7498868266183795,\n",
              "  0.8062350665604732,\n",
              "  0.8315588927490754,\n",
              "  0.846965399886557,\n",
              "  0.8580169971671388,\n",
              "  0.8552983081032948,\n",
              "  0.8749718405046182,\n",
              "  0.8770259548906267,\n",
              "  0.8744530461124201,\n",
              "  0.8865536723163844,\n",
              "  0.8796577732747946,\n",
              "  0.8904308897593732,\n",
              "  0.8970869418513104,\n",
              "  0.893569095618876,\n",
              "  0.8949442630334421,\n",
              "  0.8946777453402202,\n",
              "  0.8960089938167509,\n",
              "  0.9036671526298082,\n",
              "  0.8990023539961888,\n",
              "  0.9030452306314375,\n",
              "  0.904655326768129,\n",
              "  0.9047672462142455,\n",
              "  0.9080536912751678,\n",
              "  0.9051946594861437,\n",
              "  0.905371993706451,\n",
              "  0.9083772569249747,\n",
              "  0.9091929509484791,\n",
              "  0.9046820873840653,\n",
              "  0.9099898865041015,\n",
              "  0.9113526840748626,\n",
              "  0.9094178467071252,\n",
              "  0.9108888639172942,\n",
              "  0.9123555156548087,\n",
              "  0.911173498034812,\n",
              "  0.9099088966370488,\n",
              "  0.9083746060333183,\n",
              "  0.9090298757972474,\n",
              "  0.9103355403433958,\n",
              "  0.9095195330040413,\n",
              "  0.9108844299966371,\n",
              "  0.9152428057553956,\n",
              "  0.9134831460674158,\n",
              "  0.9119299033924961,\n",
              "  0.9121113480749803,\n",
              "  0.911111111111111,\n",
              "  0.9122531418312387,\n",
              "  0.9128826101580895,\n",
              "  0.911173498034812,\n",
              "  0.9123318385650223,\n",
              "  0.9121545720062907,\n",
              "  0.9137021658624173,\n",
              "  0.912984974209464,\n",
              "  0.9127260473997528,\n",
              "  0.9130093164215962,\n",
              "  0.9137408861469433,\n",
              "  0.9134194272880405,\n",
              "  0.9142728904847398,\n",
              "  0.9147669848399775,\n",
              "  0.9152161706906232,\n",
              "  0.914721723518851,\n",
              "  0.9148243743687577,\n",
              "  0.9152732577712939,\n",
              "  0.9152732577712939,\n",
              "  0.9151515151515152,\n",
              "  0.9154787293747897,\n",
              "  0.915459750757831,\n",
              "  0.914721723518851,\n",
              "  0.915292269718389,\n",
              "  0.9149652232443347,\n",
              "  0.9149461400359066,\n",
              "  0.9149461400359066,\n",
              "  0.9157032214614435,\n",
              "  0.9150488160700258,\n",
              "  0.9153759820426488,\n",
              "  0.9154787293747897,\n",
              "  0.9153379743992814,\n",
              "  0.9150106657684967,\n",
              "  0.9151324651998205,\n",
              "  0.9155435759209344,\n",
              "  0.9157871098136089,\n",
              "  0.9157871098136089,\n",
              "  0.9157871098136089,\n",
              "  0.915459750757831,\n",
              "  0.9154217679433898],\n",
              " 'test_score': 0.9109854123250967,\n",
              " 'train_loss_history': [12.233030884284673,\n",
              "  5.982842005143954,\n",
              "  4.732400658093099,\n",
              "  4.107038922666565,\n",
              "  3.623557952914651,\n",
              "  3.317131110533016,\n",
              "  3.0708888820775853,\n",
              "  2.865787569932112,\n",
              "  2.673694573988126,\n",
              "  2.516425656521414,\n",
              "  2.3890615171334875,\n",
              "  2.2188672944316714,\n",
              "  2.133873849872529,\n",
              "  2.0356932155729277,\n",
              "  1.9341590667334128,\n",
              "  1.862448089235411,\n",
              "  1.747316450584592,\n",
              "  1.5584183508955587,\n",
              "  1.482843624794577,\n",
              "  1.4307123389769727,\n",
              "  1.3625478817252663,\n",
              "  1.382120780588135,\n",
              "  1.311013602600323,\n",
              "  1.2351844925580062,\n",
              "  1.234377532493411,\n",
              "  1.181817140166215,\n",
              "  1.173588557036843,\n",
              "  1.1387136597332992,\n",
              "  1.0845702804449036,\n",
              "  1.0875202832728859,\n",
              "  1.0434102822007156,\n",
              "  1.0007992647294923,\n",
              "  1.0440893224843844,\n",
              "  0.9641566975848881,\n",
              "  0.9740633959845295,\n",
              "  0.9598127317240858,\n",
              "  0.9159215214684253,\n",
              "  0.8519578965630118,\n",
              "  0.8118349299656125,\n",
              "  0.800022733493114,\n",
              "  0.8025838479282349,\n",
              "  0.7741801194318636,\n",
              "  0.752980054363491,\n",
              "  0.7514592993447161,\n",
              "  0.735054983867435,\n",
              "  0.6952687882062957,\n",
              "  0.688058922140617,\n",
              "  0.6860301255241154,\n",
              "  0.6648522721031519,\n",
              "  0.6572308235281096,\n",
              "  0.6566110750821632,\n",
              "  0.6643370000396188,\n",
              "  0.6243907837417182,\n",
              "  0.6393099070533993,\n",
              "  0.6336288729051905,\n",
              "  0.6391089105699944,\n",
              "  0.6330897906633812,\n",
              "  0.6498591759073453,\n",
              "  0.6240070978487571,\n",
              "  0.620254036009781,\n",
              "  0.6161780329201165,\n",
              "  0.6064615967705493,\n",
              "  0.6306682069470563,\n",
              "  0.624138779527559,\n",
              "  0.6225655806346202,\n",
              "  0.6358530788909732,\n",
              "  0.61630057326452,\n",
              "  0.6115069947843477,\n",
              "  0.5989406611037067,\n",
              "  0.6181145232962811,\n",
              "  0.6144852060971298,\n",
              "  0.627330269869857,\n",
              "  0.622947155490635,\n",
              "  0.6241636647014167,\n",
              "  0.6099476114971432,\n",
              "  0.6222884953022003,\n",
              "  0.6161571656625102,\n",
              "  0.6224726954783042,\n",
              "  0.6115940912502018,\n",
              "  0.601717674122082,\n",
              "  0.6210030138961912,\n",
              "  0.57910346374737,\n",
              "  0.6000169341958413,\n",
              "  0.5969872479363689]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHyleLl8axOP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3178037-dfef-4dc4-8ab8-efbf09452f10"
      },
      "source": [
        "model = SequenceTagger.load('resources/taggers/example-ner/final-model.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-27 18:00:24,011 loading file resources/taggers/example-ner/final-model.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIe2-qjJhxKZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5f6ffa9-4abe-40fa-d60d-52681e58d758"
      },
      "source": [
        "strings = \"徳見傳助相達之事\"\n",
        "str_space = \" \".join(strings)\n",
        "sentence = Sentence(str_space)\n",
        "model.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "徳 <B-JINMEI> 見 <I-JINMEI> 傳 <I-JINMEI> 助 <I-JINMEI> 相 <B-EVENT> 達 <I-EVENT> 之 <B-TERMS> 事 <I-TERMS>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gubqFhMfs3wM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9c20f337-334c-43ae-e614-0737a0d1985c"
      },
      "source": [
        "!zip -r /content/resources/download.zip /content/resources/taggers/example-ner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/resources/taggers/example-ner/ (stored 0%)\n",
            "  adding: content/resources/taggers/example-ner/final-model.pt (deflated 8%)\n",
            "  adding: content/resources/taggers/example-ner/best-model.pt (deflated 8%)\n",
            "  adding: content/resources/taggers/example-ner/loss.tsv (deflated 58%)\n",
            "  adding: content/resources/taggers/example-ner/test.tsv (deflated 88%)\n",
            "  adding: content/resources/taggers/example-ner/training.log (deflated 83%)\n",
            "  adding: content/resources/taggers/example-ner/weights.txt (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8LWW9qlSX_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2fa26dc-dd2f-44d6-83ff-f4292f26864c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdFRsYsP-gJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7881bb90-2289-449e-f71c-448a28fd84e4"
      },
      "source": [
        "!ls -lh /content/resources/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1.4G\n",
            "-rw-r--r-- 1 root root 1.4G Oct 27 18:01 download.zip\n",
            "drwxr-xr-x 3 root root 4.0K Oct 27 17:08 taggers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gseUVylEHEG"
      },
      "source": [
        "!cp resources/download.zip drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}